{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Glambie anaylsis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import glob\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import statsmodels.api as sm\n",
        "from scipy import stats\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "import pymannkendall as mk\n",
        "import warnings\n",
        "import geopandas as gpd\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# Paths\n",
        "input_dir = Path(\"input\")\n",
        "output_dir = Path(\"output\")\n",
        "input_rel = input_dir / \"glambie_reference\"\n",
        "input_maps = input_dir / \"maps\"\n",
        "input_datasets = input_dir / \"input_datasets\"\n",
        "glambie_runs = input_dir / \"glambie_runs\"\n",
        "output_sensitivity = output_dir / \"sensitivity\"\n",
        "output_rel = output_dir / \"relative_change\"\n",
        "output_dir_datasets = output_dir / \"datasets\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset comparison plots\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5e646fc",
      "metadata": {},
      "source": [
        "Plot input data, colored by inclusion (green shades) and exclusion (red shades) of datasets used to produce the results of the paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "columns = {'start_dates', 'end_dates', 'changes', 'errors'}\n",
        "included_colors = ['#2ecc71', '#27ae60', '#229954', '#1e8449', '#196f3d']\n",
        "excluded_colors = ['#e74c3c', '#c0392b', '#a93226', '#922b21', '#7b241c']\n",
        "\n",
        "# included_colors = ['#2ecc71', '#00acc1', '#558b2f', '#26a69a', '#0277bd', '#7cb342', '#00695c', '#43a047', '#00838f', '#1b5e20']\n",
        "# excluded_colors = ['#e53935', '#fb8c00', '#d81b60', '#8d6e63', '#f4511e', '#ad1457', '#c62828', '#ef6c00', '#e91e63', '#6d4c41']\n",
        "\n",
        "# Load excluded list\n",
        "excluded_df = pd.read_csv(str(input_datasets / 'excluded_datasets_list.csv'))\n",
        "# excluded_df = excluded_df[excluded_df['inclusion_possible'].str.strip().str.lower() == 'no'] # plot only problematic datasets as \"excluded\"\n",
        "\n",
        "excluded_set = set()\n",
        "for _, row in excluded_df.iterrows():\n",
        "    region = row['region']\n",
        "    data_group = row['data_group']\n",
        "    dataset = str(row['dataset']).lower()\n",
        "\n",
        "    if data_group == 'demdiff_and_glaciological':\n",
        "        excluded_set.add((region, 'demdiff', dataset))\n",
        "        excluded_set.add((region, 'glaciological', dataset))\n",
        "    else:\n",
        "        excluded_set.add((region, data_group, dataset))\n",
        "\n",
        "# Datasets to completely remove from plots\n",
        "skip_datasets = set()\n",
        "\n",
        "# Load all datasets\n",
        "datasets = []\n",
        "base_dir = input_datasets\n",
        "skip_files = {'excluded_datasets_list.csv'}\n",
        "all_csv_files = [f for f in base_dir.rglob('*.csv') if f.name not in skip_files]\n",
        "\n",
        "for csv_file in all_csv_files:\n",
        "    try:\n",
        "        df = pd.read_csv(csv_file)\n",
        "        if not columns.issubset(df.columns):\n",
        "            continue\n",
        "\n",
        "        parts = csv_file.parts\n",
        "        if len(parts) < 3:\n",
        "            continue\n",
        "\n",
        "        region = parts[-3]\n",
        "        data_group = parts[-2]\n",
        "        dataset_name = csv_file.stem\n",
        "\n",
        "        if dataset_name in skip_datasets:\n",
        "            continue\n",
        "\n",
        "        unit = 'Gt' if data_group == 'gravimetry' else 'm'\n",
        "        is_excluded = (region, data_group, dataset_name.lower()) in excluded_set\n",
        "\n",
        "        datasets.append({\n",
        "            'region': region,\n",
        "            'data_group': data_group,\n",
        "            'dataset': dataset_name,\n",
        "            'unit': unit,\n",
        "            'is_excluded': is_excluded,\n",
        "            'data': df,\n",
        "            'filepath': csv_file\n",
        "        })\n",
        "    except Exception:\n",
        "        continue\n",
        "\n",
        "# Group by (region, unit)\n",
        "grouped = defaultdict(list)\n",
        "for ds in datasets:\n",
        "    grouped[(ds['region'], ds['unit'])].append(ds)\n",
        "\n",
        "# Plot per group\n",
        "for (region, unit), group_datasets in sorted(grouped.items()):\n",
        "    print(f\"Plotting {region, unit}\")\n",
        "    if not group_datasets:\n",
        "        continue\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 5))\n",
        "\n",
        "    included = [ds for ds in group_datasets if not ds['is_excluded']]\n",
        "    excluded = [ds for ds in group_datasets if ds['is_excluded']]\n",
        "\n",
        "    # Included\n",
        "    for idx, ds in enumerate(included):\n",
        "        color = included_colors[idx % len(included_colors)]\n",
        "        dfp = ds['data'].copy()\n",
        "\n",
        "        dfp['time'] = (dfp['start_dates'] + dfp['end_dates']) / 2\n",
        "        dfp['errors_abs'] = dfp['errors'].abs()\n",
        "        dfp = dfp.sort_values('time').reset_index(drop=True)\n",
        "        if len(dfp) == 0:\n",
        "            continue\n",
        "\n",
        "        x_lines, y_lines = [], []\n",
        "        for _, row in dfp.iterrows():\n",
        "            x_lines.extend([row['start_dates'], row['end_dates'], np.nan])\n",
        "            y_lines.extend([row['changes'], row['changes'], np.nan])\n",
        "        ax.plot(x_lines, y_lines, '-', linewidth=2, alpha=0.7, color=color)\n",
        "\n",
        "        for _, row in dfp.iterrows():\n",
        "            x_ribbon = [row['start_dates'], row['end_dates'], row['end_dates'], row['start_dates']]\n",
        "            y_ribbon = [\n",
        "                row['changes'] - row['errors_abs'],\n",
        "                row['changes'] - row['errors_abs'],\n",
        "                row['changes'] + row['errors_abs'],\n",
        "                row['changes'] + row['errors_abs'],\n",
        "            ]\n",
        "            ax.fill(x_ribbon, y_ribbon, color=color, alpha=0.2, edgecolor='none')\n",
        "\n",
        "    # Excluded\n",
        "    for idx, ds in enumerate(excluded):\n",
        "        color = excluded_colors[idx % len(excluded_colors)]\n",
        "        dfp = ds['data'].copy()\n",
        "\n",
        "        dfp['time'] = (dfp['start_dates'] + dfp['end_dates']) / 2\n",
        "        dfp['errors_abs'] = dfp['errors'].abs()\n",
        "        dfp = dfp.sort_values('time').reset_index(drop=True)\n",
        "        if len(dfp) == 0:\n",
        "            continue\n",
        "\n",
        "        x_lines, y_lines = [], []\n",
        "        for _, row in dfp.iterrows():\n",
        "            x_lines.extend([row['start_dates'], row['end_dates'], np.nan])\n",
        "            y_lines.extend([row['changes'], row['changes'], np.nan])\n",
        "        ax.plot(x_lines, y_lines, '-', linewidth=2, alpha=0.7, color=color)\n",
        "\n",
        "        for _, row in dfp.iterrows():\n",
        "            x_ribbon = [row['start_dates'], row['end_dates'], row['end_dates'], row['start_dates']]\n",
        "            y_ribbon = [\n",
        "                row['changes'] - row['errors_abs'],\n",
        "                row['changes'] - row['errors_abs'],\n",
        "                row['changes'] + row['errors_abs'],\n",
        "                row['changes'] + row['errors_abs'],\n",
        "            ]\n",
        "            ax.fill(x_ribbon, y_ribbon, color=color, alpha=0.2, edgecolor='none')\n",
        "\n",
        "    # Legend\n",
        "    legend_elements = []\n",
        "    for idx, ds in enumerate(included):\n",
        "        color = included_colors[idx % len(included_colors)]\n",
        "        legend_elements.append(plt.Line2D([0], [0], color=color, lw=2,\n",
        "                                         label=f\"{ds['dataset']} (Included)\"))\n",
        "    for idx, ds in enumerate(excluded):\n",
        "        color = excluded_colors[idx % len(excluded_colors)]\n",
        "        legend_elements.append(plt.Line2D([0], [0], color=color, lw=2,\n",
        "                                         label=f\"{ds['dataset']} (Excluded)\"))\n",
        "\n",
        "    unit_label = 'Gravimetry (Gt)' if unit == 'Gt' else 'All Other Methods (m)'\n",
        "    ax.set_xlabel('Time (year)')\n",
        "    ax.set_ylabel(f'Change ({unit})')\n",
        "    ax.set_title(\n",
        "        f'{region.replace(\"_\", \" \").title()} ({unit_label})')\n",
        "    ax.grid(True, alpha=0.3, linestyle='--')\n",
        "\n",
        "    if legend_elements:\n",
        "        ax.legend(handles=legend_elements, loc='best', fontsize=9, ncol=2)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    safe_region = region.replace('/', '_').replace('\\\\', '_')\n",
        "    output_path = output_dir_datasets / f\"{safe_region}_{unit}.png\"\n",
        "    plt.savefig(output_path, dpi=200, bbox_inches='tight')\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sensitivity analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a36d87e",
      "metadata": {},
      "source": [
        "Comparison of difference when including all possible input datasets in the algorithm. \n",
        "- Root mean squared difference\n",
        "- Mean absolute difference\n",
        "- Relative difference in overall mass change\n",
        "- Absolute difference in overall mass change\n",
        "- Pearson correlation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5701c5b9",
      "metadata": {},
      "source": [
        "### Barcharts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Paths and configuration\n",
        "run1 = glambie_runs / \"Reanalysis_RGI_6_default\"\n",
        "run2 = glambie_runs / \"Reanalysis_RGI_6_including_most\"\n",
        "\n",
        "glacier_mass_file = input_rel / \"glacier_mass_2000.csv\"\n",
        "glacier_mass_df = pd.read_csv(str(glacier_mass_file), sep=\";\")\n",
        "glacier_mass_dict = dict(zip(glacier_mass_df[\"Region\"], glacier_mass_df[\"Mass\"]))\n",
        "\n",
        "# Region mappings\n",
        "regions_bar = {\n",
        "    \"1_alaska\": \"Alaska\",\n",
        "    \"2_western_canada_us\": \"W. Canada & US\",\n",
        "    \"3_arctic_canada_north\": \"Arctic Canada N.\",\n",
        "    \"4_arctic_canada_south\": \"Arctic Canada S.\",\n",
        "    \"5_greenland_periphery\": \"Greenland Per.\",\n",
        "    \"6_iceland\": \"Iceland\",\n",
        "    \"7_svalbard\": \"Svalbard\",\n",
        "    \"8_scandinavia\": \"Scandinavia\",\n",
        "    \"9_russian_arctic\": \"Russian Arctic\",\n",
        "    \"10_north_asia\": \"North Asia\",\n",
        "    \"11_central_europe\": \"Central Europe\",\n",
        "    \"12_caucasus_middle_east\": \"Caucasus & M.E.\",\n",
        "    \"13_central_asia\": \"Central Asia\",\n",
        "    \"14_south_asia_west\": \"South Asia W.\",\n",
        "    \"15_south_asia_east\": \"South Asia E.\",\n",
        "    \"16_low_latitudes\": \"Low Latitudes\",\n",
        "    \"17_southern_andes\": \"Southern Andes\",\n",
        "    \"18_new_zealand\": \"New Zealand\",\n",
        "    \"19_antarctic_and_subantarctic\": \"Antarctic & Sub.\",\n",
        "}\n",
        "\n",
        "mass_lookup = {\n",
        "    \"Alaska\": \"Alaska\",\n",
        "    \"W. Canada & US\": \"Western Canada and USA\",\n",
        "    \"Arctic Canada N.\": \"Arctic Canada north\",\n",
        "    \"Arctic Canada S.\": \"Arctic Canada south\",\n",
        "    \"Greenland Per.\": \"Greenland periphery\",\n",
        "    \"Iceland\": \"Iceland\",\n",
        "    \"Svalbard\": \"Svalbard and Jan Mayen\",\n",
        "    \"Scandinavia\": \"Scandinavia\",\n",
        "    \"Russian Arctic\": \"Russian Arctic\",\n",
        "    \"North Asia\": \"North Asia\",\n",
        "    \"Central Europe\": \"Central Europe\",\n",
        "    \"Caucasus & M.E.\": \"Caucasus and Middle East\",\n",
        "    \"Central Asia\": \"Central Asia\",\n",
        "    \"South Asia W.\": \"South Asia west\",\n",
        "    \"South Asia E.\": \"South Asia east\",\n",
        "    \"Low Latitudes\": \"Low latitudes\",\n",
        "    \"Southern Andes\": \"Southern Andes\",\n",
        "    \"New Zealand\": \"New Zealand\",\n",
        "    \"Antarctic & Sub.\": \"Antarctic and subantarctic islands\",\n",
        "    \"Global\": \"Global\",\n",
        "}\n",
        "\n",
        "regions_map = {\n",
        "    \"1_alaska\":                      (\"Alaska\",            63.0, -150.0, 1),\n",
        "    \"2_western_canada_us\":           (\"W. Canada & US\",    50.0, -122.0, 2),\n",
        "    \"3_arctic_canada_north\":         (\"Arctic Canada N.\",  77.0,  -82.0, 3),\n",
        "    \"4_arctic_canada_south\":         (\"Arctic Canada S.\",  66.0,  -70.0, 4),\n",
        "    \"5_greenland_periphery\":         (\"Greenland Per.\",    72.0,  -42.0, 5),\n",
        "    \"6_iceland\":                     (\"Iceland\",           65.0,  -19.0, 6),\n",
        "    \"7_svalbard\":                    (\"Svalbard\",          78.0,   17.0, 7),\n",
        "    \"8_scandinavia\":                 (\"Scandinavia\",       67.0,   15.0, 8),\n",
        "    \"9_russian_arctic\":              (\"Russian Arctic\",    77.0,   60.0, 9),\n",
        "    \"10_north_asia\":                 (\"North Asia\",        50.0,   90.0, 10),\n",
        "    \"11_central_europe\":             (\"Central Europe\",    47.0,   11.0, 11),\n",
        "    \"12_caucasus_middle_east\":       (\"Caucasus & M.E.\",   42.0,   44.0, 12),\n",
        "    \"13_central_asia\":               (\"Central Asia\",      40.0,   75.0, 13),\n",
        "    \"14_south_asia_west\":            (\"South Asia W.\",     35.0,   74.0, 14),\n",
        "    \"15_south_asia_east\":            (\"South Asia E.\",     30.0,   90.0, 15),\n",
        "    \"16_low_latitudes\":              (\"Low Latitudes\",     -1.0,  -78.0, 16),\n",
        "    \"17_southern_andes\":             (\"Southern Andes\",   -47.0,  -73.0, 17),\n",
        "    \"18_new_zealand\":                (\"New Zealand\",      -44.0,  170.0, 18),\n",
        "    \"19_antarctic_and_subantarctic\": (\"Antarctic & Sub.\", -70.0,    0.0, 19),\n",
        "}\n",
        "\n",
        "label_positions = {\n",
        "    \"Alaska\":            (-170.0, 55.0),\n",
        "    \"W. Canada & US\":    (-140.0, 42.0),\n",
        "    \"Arctic Canada N.\":  (-100.0, 82.0),\n",
        "    \"Arctic Canada S.\":  (-85.0, 72.0),\n",
        "    \"Greenland Per.\":    (-50.0, 78.0),\n",
        "    \"Iceland\":           (-30.0, 68.0),\n",
        "    \"Svalbard\":          (10.0, 82.0),\n",
        "    \"Scandinavia\":       (5.0, 72.0),\n",
        "    \"Russian Arctic\":    (70.0, 82.0),\n",
        "    \"North Asia\":        (110.0, 55.0),\n",
        "    \"Central Europe\":    (0.0, 50.0),\n",
        "    \"Caucasus & M.E.\":   (55.0, 48.0),\n",
        "    \"Central Asia\":      (85.0, 45.0),\n",
        "    \"South Asia W.\":     (65.0, 30.0),\n",
        "    \"South Asia E.\":     (100.0, 25.0),\n",
        "    \"Low Latitudes\":     (-90.0, -8.0),\n",
        "    \"Southern Andes\":    (-80.0, -52.0),\n",
        "    \"New Zealand\":       (175.0, -50.0),\n",
        "    \"Antarctic & Sub.\":  (-10.0, -75.0),\n",
        "}\n",
        "\n",
        "def compute_all_metrics(df1, df2, glacier_mass):\n",
        "    merged = pd.merge(df1, df2, on=\"start_dates\", suffixes=(\"_run1\", \"_run2\"))\n",
        "    diff = merged[\"changes_run1\"] - merged[\"changes_run2\"]\n",
        "    rmse = np.sqrt(np.mean(diff ** 2))\n",
        "    mae = np.mean(np.abs(diff))\n",
        "    cumul_run1 = merged[\"changes_run1\"].sum()\n",
        "    cumul_run2 = merged[\"changes_run2\"].sum()\n",
        "    if abs(cumul_run1) > 0.01:\n",
        "        rel_diff = (cumul_run2 - cumul_run1) / abs(cumul_run1) * 100.0\n",
        "    else:\n",
        "        rel_diff = 0.0\n",
        "    abs_diff = cumul_run2 - cumul_run1\n",
        "    rmse_pct = (rmse / glacier_mass * 100.0) if glacier_mass else 0.0\n",
        "    try:\n",
        "        corr, _ = spearmanr(df1[\"changes\"], df2[\"changes\"])\n",
        "    except:\n",
        "        corr = 0\n",
        "    return rmse, mae, rel_diff, abs_diff, rmse_pct, corr\n",
        "\n",
        "# Initialize lists to store metrics\n",
        "region_names = []\n",
        "rmse_values = []\n",
        "mae_values = []\n",
        "rel_diff_values = []\n",
        "rmse_pct_values = []\n",
        "abs_diff_values = []\n",
        "corr_values = []  # New list for correlation values\n",
        "\n",
        "for region_dir, display_name in regions_bar.items():\n",
        "    region_key = \"_\".join(region_dir.split(\"_\")[1:])\n",
        "    csv1 = run1 / region_dir / \"consensus\" / \"csvs\" / f\"consensus_calendar_year_gt_{region_key}.csv\"\n",
        "    csv2 = run2 / region_dir / \"consensus\" / \"csvs\" / f\"consensus_calendar_year_gt_{region_key}.csv\"\n",
        "\n",
        "    df1 = pd.read_csv(str(csv1))\n",
        "    df2 = pd.read_csv(str(csv2))\n",
        "\n",
        "    mass_key = mass_lookup.get(display_name, display_name)\n",
        "    glacier_mass = glacier_mass_dict.get(mass_key, None)\n",
        "\n",
        "    rmse, mae, rel_diff, abs_diff, rmse_pct, corr = compute_all_metrics(df1, df2, glacier_mass)\n",
        "\n",
        "    region_names.append(display_name)\n",
        "    rmse_values.append(rmse)\n",
        "    mae_values.append(mae)\n",
        "    rel_diff_values.append(rel_diff)\n",
        "    rmse_pct_values.append(rmse_pct)\n",
        "    abs_diff_values.append(abs_diff)\n",
        "    corr_values.append(corr)\n",
        "\n",
        "# Compute metrics for the global data\n",
        "csv1_global = run1 / \"0_global\" / \"consensus\" / \"csvs\" / \"global_gt.csv\"\n",
        "csv2_global = run2 / \"0_global\" / \"consensus\" / \"csvs\" / \"global_gt.csv\"\n",
        "df1 = pd.read_csv(str(csv1_global))\n",
        "df2 = pd.read_csv(str(csv2_global))\n",
        "rmse, mae, rel_diff, abs_diff, rmse_pct, corr = compute_all_metrics(df1, df2, glacier_mass_dict.get(\"Global\", None))\n",
        "region_names.append(\"Global\")\n",
        "rmse_values.append(rmse)\n",
        "mae_values.append(mae)\n",
        "rel_diff_values.append(rel_diff)\n",
        "rmse_pct_values.append(rmse_pct)\n",
        "abs_diff_values.append(abs_diff)\n",
        "corr_values.append(corr)\n",
        "\n",
        "# Plotting code for RMSE, MAE, rel_diff, abs_diff (unchanged)\n",
        "fig1, ax1 = plt.subplots(figsize=(14, 7))\n",
        "bars1 = ax1.barh(range(len(region_names)), rmse_values)\n",
        "ax1.set_yticks(range(len(region_names)))\n",
        "ax1.set_yticklabels(region_names)\n",
        "ax1.invert_yaxis()\n",
        "ax1.set_xlabel(\"RMSE of Mass Change Difference (Gt)\")\n",
        "ax1.set_title(\"RMSE Difference \\n(default vs. all datasets)\")\n",
        "max_rmse = max(rmse_values)\n",
        "for i, (val, bar) in enumerate(zip(rmse_values, bars1)):\n",
        "    ax1.text(val + 0.02 * max_rmse, i, f\"{val:.2f}\", va=\"center\")\n",
        "ax1.set_xlim(0, max_rmse * 1.15)\n",
        "fig1.tight_layout()\n",
        "# Removing for now because too abstract to be useful\n",
        "# path1 = output_sensitivity / \"rmse_difference_between_runs.png\"\n",
        "# fig1.savefig(str(path1), dpi=200, bbox_inches=\"tight\")\n",
        "\n",
        "fig2, ax2 = plt.subplots(figsize=(14, 7))\n",
        "bars2 = ax2.barh(range(len(region_names)), mae_values)\n",
        "ax2.set_yticks(range(len(region_names)))\n",
        "ax2.set_yticklabels(region_names)\n",
        "ax2.invert_yaxis()\n",
        "ax2.set_xlabel(\"MAE of Mass Change Difference (Gt)\")\n",
        "ax2.set_title(\"MAE Difference \\n(default vs. all datasets)\")\n",
        "max_mae = max(mae_values)\n",
        "for i, (val, bar) in enumerate(zip(mae_values, bars2)):\n",
        "    ax2.text(val + 0.02 * max_mae, i, f\"{val:.2f}\", va=\"center\")\n",
        "ax2.set_xlim(0, max_mae * 1.15)\n",
        "fig2.tight_layout()\n",
        "# Removing for now because too abstract to be useful\n",
        "# path2 = output_sensitivity / \"mae_difference_between_runs.png\"\n",
        "# fig2.savefig(str(path2), dpi=200, bbox_inches=\"tight\")\n",
        "\n",
        "fig3, ax3 = plt.subplots(figsize=(14, 7))\n",
        "bars3 = ax3.barh(range(len(region_names)), rel_diff_values)\n",
        "ax3.set_yticks(range(len(region_names)))\n",
        "ax3.set_yticklabels(region_names)\n",
        "ax3.invert_yaxis()\n",
        "ax3.set_xlabel(\"Relative Change in Cumulative Mass Loss (%)\")\n",
        "ax3.set_title(\"Relative Difference in Total Mass Change\\n\"\n",
        "              \"(default vs. all datasets; positive = more loss, negative = less loss)\")\n",
        "ax3.axvline(0, color=\"black\", linewidth=0.8)\n",
        "max_abs_rel = max(abs(v) for v in rel_diff_values)\n",
        "for i, (val, bar) in enumerate(zip(rel_diff_values, bars3)):\n",
        "    if val >= 0:\n",
        "        ax3.text(val + 0.02 * max_abs_rel, i, f\"+{val:.1f}%\", va=\"center\")\n",
        "    else:\n",
        "        ax3.text(val - 0.02 * max_abs_rel, i, f\"{val:.1f}%\", va=\"center\", ha=\"right\")\n",
        "pad = max_abs_rel * 0.15\n",
        "ax3.set_xlim(min(rel_diff_values) - pad, max(rel_diff_values) + pad)\n",
        "fig3.tight_layout()\n",
        "path3 = output_sensitivity / \"relative_difference_between_runs.png\"\n",
        "fig3.savefig(str(path3), dpi=200, bbox_inches=\"tight\")\n",
        "\n",
        "fig4, ax4 = plt.subplots(figsize=(14, 7))\n",
        "bars4 = ax4.barh(range(len(region_names)), abs_diff_values)\n",
        "ax4.set_yticks(range(len(region_names)))\n",
        "ax4.set_yticklabels(region_names)\n",
        "ax4.invert_yaxis()\n",
        "ax4.set_xlabel(\"Absolute Mass Change Difference (Gt)\")\n",
        "ax4.set_title(\"Absolute Mass Change Difference \\n(default vs. all datasets)\")\n",
        "ax4.axvline(0, color=\"black\", linewidth=0.8)\n",
        "max_abs_diff = max(abs(v) for v in abs_diff_values)\n",
        "for i, (val, rel, bar) in enumerate(zip(abs_diff_values, rel_diff_values, bars4)):\n",
        "    if val >= 0:\n",
        "        ax4.text(val + 0.02 * max_abs_diff, i, f\"+{val:.2f} ({rel:+.1f}%)\", va=\"center\")\n",
        "    else:\n",
        "        ax4.text(val - 0.02 * max_abs_diff, i, f\"{val:.2f} ({rel:+.1f}%)\", va=\"center\", ha=\"right\")\n",
        "min_val = min(abs_diff_values)\n",
        "max_val = max(abs_diff_values)\n",
        "pad = max_abs_diff * 0.30\n",
        "ax4.set_xlim(min_val - pad, max_val + pad)\n",
        "fig4.tight_layout()\n",
        "path4 = output_sensitivity / \"absolute_difference_between_runs.png\"\n",
        "fig4.savefig(str(path4), dpi=200, bbox_inches=\"tight\")\n",
        "\n",
        "# New plot for correlation with annotations\n",
        "fig5, ax5 = plt.subplots(figsize=(14, 7))\n",
        "bars5 = ax5.barh(range(len(region_names)), corr_values)\n",
        "ax5.set_yticks(range(len(region_names)))\n",
        "ax5.set_yticklabels(region_names)\n",
        "ax5.invert_yaxis()\n",
        "ax5.set_xlabel(\"Correlation Coefficient\")\n",
        "ax5.set_title(\"Correlation between Runs\\n(default vs. all datasets)\")\n",
        "ax5.set_xlim(-0.1, 1.1)  # Slightly extend the x-axis to fit annotations\n",
        "\n",
        "# Add annotations for correlation values\n",
        "for i, (val, bar) in enumerate(zip(corr_values, bars5)):\n",
        "    if val >= 0:\n",
        "        ax5.text(val + 0.02, i, f\"{val:.2f}\", va=\"center\")\n",
        "    else:\n",
        "        ax5.text(val + 0.08, i, f\"{val:.2f}\", va=\"center\", ha=\"right\")\n",
        "\n",
        "fig5.tight_layout()\n",
        "path5 = output_sensitivity / \"correlation_between_runs.png\"\n",
        "fig5.savefig(str(path5), dpi=200, bbox_inches=\"tight\")\n",
        "plt.close('all')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecdf7f67",
      "metadata": {},
      "source": [
        "### Map visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1346ce4",
      "metadata": {},
      "source": [
        "Create maps which show differences between dataset inclusions per region. \n",
        "- Root mean squared difference\n",
        "- Mean absolute difference\n",
        "- Relative difference in overall mass change\n",
        "- Absolute difference in overall mass change"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Map plots\n",
        "glacreg_path = input_maps / \"GlacReg_2023\" / \"GTN-G_202307_o1regions.shp\"\n",
        "glacier_regions = gpd.read_file(str(glacreg_path))\n",
        "\n",
        "data = []\n",
        "for i, (region_dir, (display_name, lat, lon, region_num)) in enumerate(regions_map.items()):\n",
        "    data.append({\n",
        "        \"name\": display_name,\n",
        "        \"lat\": lat,\n",
        "        \"lon\": lon,\n",
        "        \"region_num\": region_num,\n",
        "        \"rmse\": rmse_values[i],\n",
        "        \"mae\": mae_values[i],\n",
        "        \"rel_diff\": rel_diff_values[i],\n",
        "        \"abs_diff\": abs_diff_values[i],\n",
        "        \"corr\": corr_values[i],\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Global is the last element in the barchart lists\n",
        "global_metrics = {\n",
        "    \"rmse\": rmse_values[-1],\n",
        "    \"mae\": mae_values[-1],\n",
        "    \"rel_diff\": rel_diff_values[-1],\n",
        "    \"abs_diff\": abs_diff_values[-1],\n",
        "    \"corr\": corr_values[-1],\n",
        "}\n",
        "\n",
        "map_configs = [\n",
        "    # {\n",
        "    #     \"metric\": \"rmse\",\n",
        "    #     \"title\": \"RMSE Difference Between Glambie Runs\\n(default vs. all datasets)\",\n",
        "    #     \"cmap\": \"YlOrRd\",\n",
        "    #     \"label\": \"RMSE (Gt)\",\n",
        "    #     \"diverging\": False,\n",
        "    #     \"output\": \"map_rmse_difference.png\",\n",
        "    #     \"fmt\": \".2f\",\n",
        "    #     \"unit\": \" Gt\",\n",
        "    # },\n",
        "    # {\n",
        "    #     \"metric\": \"mae\",\n",
        "    #     \"title\": \"MAE Difference Between Glambie Runs\\n(default vs. all datasets)\",\n",
        "    #     \"cmap\": \"YlOrRd\",\n",
        "    #     \"label\": \"MAE (Gt)\",\n",
        "    #     \"diverging\": False,\n",
        "    #     \"output\": \"map_mae_difference.png\",\n",
        "    #     \"fmt\": \".2f\",\n",
        "    #     \"unit\": \" Gt\",\n",
        "    # },\n",
        "    {\n",
        "        \"metric\": \"rel_diff\",\n",
        "        \"title\": \"Relative Difference in Total Mass Change\\n(default vs. all datasets)\",\n",
        "        \"cmap\": \"RdBu_r\",\n",
        "        \"label\": \"Relative Difference (%)\",\n",
        "        \"diverging\": True,\n",
        "        \"output\": \"map_relative_difference.png\",\n",
        "        \"fmt\": \"+.1f\",\n",
        "        \"unit\": \"%\",\n",
        "    },\n",
        "    {\n",
        "        \"metric\": \"abs_diff\",\n",
        "        \"title\": \"Absolute Mass Change Difference Between Glambie Runs\\n(default vs. all datasets)\",\n",
        "        \"cmap\": \"RdBu_r\",\n",
        "        \"label\": \"Absolute Difference (Gt)\",\n",
        "        \"diverging\": True,\n",
        "        \"output\": \"map_absolute_difference.png\",\n",
        "        \"fmt\": \"+.2f\",\n",
        "        \"unit\": \" Gt\",\n",
        "    },\n",
        "    {\n",
        "        \"metric\": \"corr\",\n",
        "        \"title\": \"Correlation Between Glambie Runs\\n(default vs. all datasets)\",\n",
        "        \"cmap\": \"RdYlGn\",\n",
        "        \"label\": \"Correlation\",\n",
        "        \"diverging\": False,\n",
        "        \"output\": \"map_correlation.png\",\n",
        "        \"fmt\": \".2f\",\n",
        "        \"unit\": \"\",\n",
        "    },\n",
        "]\n",
        "\n",
        "for cfg in map_configs:\n",
        "    metric = cfg[\"metric\"]\n",
        "    title = cfg[\"title\"]\n",
        "    cmap = cfg[\"cmap\"]\n",
        "    label = cfg[\"label\"]\n",
        "    diverging = cfg[\"diverging\"]\n",
        "    output_path = output_sensitivity / cfg[\"output\"]\n",
        "    fmt = cfg[\"fmt\"]\n",
        "    unit = cfg[\"unit\"]\n",
        "\n",
        "    values = df[metric].values\n",
        "    global_val = global_metrics.get(metric, None)\n",
        "\n",
        "    fig = plt.figure(figsize=(20, 11))\n",
        "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.Robinson())\n",
        "\n",
        "    ax.add_feature(cfeature.OCEAN, facecolor='white', zorder=0)\n",
        "    ax.add_feature(cfeature.LAND, facecolor='#e0e0e0', edgecolor='#aaaaaa', linewidth=0.3, zorder=1)\n",
        "    ax.add_feature(cfeature.COASTLINE, linewidth=0.4, edgecolor='#666666', zorder=2)\n",
        "\n",
        "    glaciers = cfeature.NaturalEarthFeature(\n",
        "        'physical', 'glaciated_areas', '50m',\n",
        "        edgecolor='#2e5f7f', facecolor='#4a8fc4', linewidth=0.2\n",
        "    )\n",
        "    ax.add_feature(glaciers, zorder=3, alpha=0.7)\n",
        "\n",
        "    if glacier_regions is not None:\n",
        "        ax.add_geometries(\n",
        "            glacier_regions.geometry,\n",
        "            crs=ccrs.PlateCarree(),\n",
        "            facecolor='none',\n",
        "            edgecolor='#5a5a5a',\n",
        "            linewidth=1.0,\n",
        "            linestyle='--',\n",
        "            zorder=4,\n",
        "            alpha=0.6\n",
        "        )\n",
        "    ax.set_global()\n",
        "\n",
        "    vals = np.array(values)\n",
        "    abs_vals = np.abs(vals)\n",
        "\n",
        "    if global_val is not None:\n",
        "        size_scale = max(abs_vals.max(), abs(global_val))\n",
        "    else:\n",
        "        size_scale = abs_vals.max()\n",
        "\n",
        "    sizes = (abs_vals / size_scale) * 5000\n",
        "\n",
        "    if diverging:\n",
        "        all_vals = list(vals) + ([global_val] if global_val is not None else [])\n",
        "        vmax_abs = max(abs(min(all_vals)), abs(max(all_vals)))\n",
        "        vmin, vmax = -vmax_abs, vmax_abs\n",
        "        norm = mcolors.TwoSlopeNorm(vmin=vmin, vcenter=0, vmax=vmax)\n",
        "    else:\n",
        "        vmin = 0\n",
        "        all_vals = list(vals) + ([global_val] if global_val is not None else [])\n",
        "        vmax = max(all_vals)\n",
        "        norm = mcolors.Normalize(vmin=vmin, vmax=vmax)\n",
        "\n",
        "    sc = ax.scatter(\n",
        "        df[\"lon\"], df[\"lat\"],\n",
        "        c=vals, s=sizes,\n",
        "        cmap=cmap, norm=norm,\n",
        "        edgecolors=\"0.2\", linewidths=1.0,\n",
        "        zorder=8, alpha=0.75,\n",
        "        transform=ccrs.PlateCarree()\n",
        "    )\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        region_name = row[\"name\"]\n",
        "        val = row[metric]\n",
        "        val_str = f\"{val:{fmt}}{unit}\"\n",
        "\n",
        "        if region_name in label_positions:\n",
        "            label_lon, label_lat = label_positions[region_name]\n",
        "\n",
        "            ax.text(\n",
        "                label_lon, label_lat,\n",
        "                f\"{region_name}\\n{val_str}\",\n",
        "                fontsize=7, ha=\"center\", va='center',\n",
        "                color=\"0.1\",\n",
        "                bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"0.4\", alpha=0.85, linewidth=0.5),\n",
        "                transform=ccrs.PlateCarree(),\n",
        "                zorder=12\n",
        "            )\n",
        "\n",
        "            ax.plot(\n",
        "                [label_lon, row[\"lon\"]], [label_lat, row[\"lat\"]],\n",
        "                color='0.5', linewidth=0.4, linestyle='-', alpha=0.5,\n",
        "                transform=ccrs.PlateCarree(),\n",
        "                zorder=7\n",
        "            )\n",
        "\n",
        "    if global_val is not None:\n",
        "        global_lon, global_lat = 0.0, -20.0\n",
        "        global_size = (abs(global_val) / size_scale) * 5000\n",
        "\n",
        "        ax.scatter(\n",
        "            [global_lon], [global_lat],\n",
        "            c=[global_val], s=[global_size * 1.5],\n",
        "            cmap=cmap, norm=norm,\n",
        "            edgecolors=\"0.1\", linewidths=1.0,\n",
        "            zorder=11, alpha=0.9,\n",
        "            marker=\"o\",\n",
        "            transform=ccrs.PlateCarree()\n",
        "        )\n",
        "\n",
        "        val_str = f\"{global_val:{fmt}}{unit}\"\n",
        "        ax.text(\n",
        "            global_lon, global_lat - 8,\n",
        "            f\"Global\\n{val_str}\",\n",
        "            fontsize=9, fontweight=\"bold\", ha=\"center\", va='top',\n",
        "            color=\"0.05\",\n",
        "            bbox=dict(boxstyle=\"round,pad=0.35\", fc=\"white\", ec=\"0.3\", alpha=0.95, linewidth=1),\n",
        "            transform=ccrs.PlateCarree(),\n",
        "            zorder=12\n",
        "        )\n",
        "\n",
        "    cb = plt.colorbar(sc, ax=ax, shrink=0.5, pad=0.03, aspect=20, orientation='vertical')\n",
        "    cb.set_label(label, fontsize=11)\n",
        "    cb.ax.tick_params(labelsize=9)\n",
        "\n",
        "    ax.set_title(title, fontsize=13, pad=15)\n",
        "\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(str(output_path), dpi=200)\n",
        "    plt.close(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Relative change calculations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "glacier_mass_2000_path = input_rel / \"glacier_mass_2000.csv\"\n",
        "calendar_years_path = input_rel / \"calendar_years\"\n",
        "\n",
        "mass_2000 = pd.read_csv(str(glacier_mass_2000_path), sep=';')\n",
        "file_to_mass_data = {}\n",
        "for _, row in mass_2000.iterrows():\n",
        "    file_to_mass_data[row['File']] = {\n",
        "        'region': row['Region'],\n",
        "        'mass': row['Mass'],\n",
        "        'error': row['Error']\n",
        "    }\n",
        "annual_changes = {}\n",
        "\n",
        "for csv_file in sorted(glob.glob(str(calendar_years_path / \"*.csv\"))):\n",
        "    annual_changes[Path(csv_file).name] = pd.read_csv(csv_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate annual relative change with uncertainty propagation\n",
        "results = []\n",
        "\n",
        "for filename, df_changes in sorted(annual_changes.items()):\n",
        "    matched_mass_data = file_to_mass_data[filename]\n",
        "    current_mass = matched_mass_data['mass']\n",
        "    current_mass_error = matched_mass_data['error']\n",
        "\n",
        "    df_changes_sorted = df_changes.sort_values('start_dates').reset_index(drop=True)\n",
        "\n",
        "    for idx, row in df_changes_sorted.iterrows():\n",
        "        annual_change = row['combined_gt']\n",
        "        annual_change_error = row['combined_gt_errors']\n",
        "\n",
        "        relative_change = annual_change / current_mass\n",
        "\n",
        "        # error propagation\n",
        "        relative_change_error_term1 = (annual_change_error / annual_change) ** 2\n",
        "        relative_change_error_term2 = (current_mass_error / current_mass) ** 2\n",
        "        relative_change_error = abs(relative_change) * np.sqrt(relative_change_error_term1 + relative_change_error_term2)\n",
        "\n",
        "        results.append({\n",
        "            'region': matched_mass_data['region'],\n",
        "            'year_start': int(row['start_dates']),\n",
        "            'year_end': int(row['end_dates']),\n",
        "            'glacier_mass_at_start': current_mass,\n",
        "            'glacier_mass_error_at_start': current_mass_error,\n",
        "            'annual_change_gt': annual_change,\n",
        "            'annual_change_error': annual_change_error,\n",
        "            'relative_change': relative_change,\n",
        "            'relative_change_error': relative_change_error,\n",
        "            'relative_change_pct': relative_change * 100,\n",
        "            'relative_change_error_pct': relative_change_error * 100\n",
        "        })\n",
        "\n",
        "        current_mass = current_mass + annual_change\n",
        "        current_mass_error = np.sqrt(current_mass_error**2 + annual_change_error**2)\n",
        "\n",
        "results_df = pd.DataFrame(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54ea7535",
      "metadata": {},
      "source": [
        "### Combined relative change and mass evolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "all_regions = sorted(results_df['region'].unique())\n",
        "global_regions = [r for r in all_regions if r.lower() == 'global']\n",
        "other_regions = [r for r in all_regions if r.lower() != 'global']\n",
        "\n",
        "ax1 = axes[0]\n",
        "for region in global_regions:\n",
        "    region_data = results_df[results_df['region'] == region].sort_values('year_start')\n",
        "    ax1.plot(region_data['year_start'], region_data['relative_change_pct'],\n",
        "             marker='o', label=region, alpha=0.8, linewidth=2, color='darkblue')\n",
        "    ax1.fill_between(region_data['year_start'],\n",
        "                      region_data['relative_change_pct'] - region_data['relative_change_error_pct'],\n",
        "                      region_data['relative_change_pct'] + region_data['relative_change_error_pct'],\n",
        "                      alpha=0.2, color='darkblue')\n",
        "ax1.set_xlabel('Year Start', fontsize=12)\n",
        "ax1.set_ylabel('Relative Change (%)', fontsize=12)\n",
        "ax1.set_title('Global Annual Relative Glacier Mass Change', fontsize=14)\n",
        "ax1.legend(fontsize=10, loc='lower left')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
        "\n",
        "ax2 = axes[1]\n",
        "for region in other_regions:\n",
        "    region_data = results_df[results_df['region'] == region].sort_values('year_start')\n",
        "    ax2.plot(region_data['year_start'], region_data['relative_change_pct'],\n",
        "             marker='o', label=region, alpha=0.8, linewidth=2)\n",
        "    ax2.fill_between(region_data['year_start'],\n",
        "                      region_data['relative_change_pct'] - region_data['relative_change_error_pct'],\n",
        "                      region_data['relative_change_pct'] + region_data['relative_change_error_pct'],\n",
        "                      alpha=0.15)\n",
        "ax2.set_xlabel('Year Start', fontsize=12)\n",
        "ax2.set_ylabel('Relative Change (%)', fontsize=12)\n",
        "ax2.set_title('Regional Annual Relative Glacier Mass Change', fontsize=14)\n",
        "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_rel / 'relative_change_plots.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4b57316",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "ax3 = axes[0]\n",
        "\n",
        "for region in global_regions:\n",
        "    region_data = results_df[results_df['region'] == region].sort_values('year_start')\n",
        "    ax3.plot(region_data['year_start'], region_data['glacier_mass_at_start'],\n",
        "             marker='s', label=region, alpha=0.8, linewidth=2, color='darkblue')\n",
        "    ax3.fill_between(region_data['year_start'],\n",
        "                      region_data['glacier_mass_at_start'] - region_data['glacier_mass_error_at_start'],\n",
        "                      region_data['glacier_mass_at_start'] + region_data['glacier_mass_error_at_start'],\n",
        "                      alpha=0.2, color='darkblue')\n",
        "ax3.set_xlabel('Year Start', fontsize=12)\n",
        "ax3.set_ylabel('Glacier Mass (Gt)', fontsize=12)\n",
        "ax3.set_title('Global Glacier Mass', fontsize=14)\n",
        "ax3.legend(fontsize=10)\n",
        "ax3.grid(True, alpha=0.3)\n",
        "ax3.set_ylim(bottom=0)\n",
        "ax4 = axes[1]\n",
        "\n",
        "for region in other_regions:\n",
        "    region_data = results_df[results_df['region'] == region].sort_values('year_start')\n",
        "    ax4.plot(region_data['year_start'], region_data['glacier_mass_at_start'],\n",
        "             marker='s', label=region, alpha=0.8, linewidth=2)\n",
        "    ax4.fill_between(region_data['year_start'],\n",
        "                      region_data['glacier_mass_at_start'] - region_data['glacier_mass_error_at_start'],\n",
        "                      region_data['glacier_mass_at_start'] + region_data['glacier_mass_error_at_start'],\n",
        "                      alpha=0.15)\n",
        "ax4.set_xlabel('Year Start', fontsize=12)\n",
        "ax4.set_ylabel('Glacier Mass (Gt)', fontsize=12)\n",
        "ax4.set_title('Regional Glacier Mass', fontsize=14)\n",
        "ax4.legend(bbox_to_anchor=(1, 0.8), loc='upper left', fontsize=9)\n",
        "ax4.grid(True, alpha=0.3)\n",
        "ax4.set_ylim(bottom=0)\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_rel / 'glacier_mass_evolution.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a65656c9",
      "metadata": {},
      "source": [
        "### Global relative and absolute change with trend test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "all_regions = sorted(results_df['region'].unique())\n",
        "global_regions = [r for r in all_regions if r.lower() == 'global']\n",
        "for region in global_regions:\n",
        "    region_data = results_df[results_df['region'] == region].sort_values('year_start')\n",
        "    ax.plot(region_data['year_start'], region_data['relative_change_pct'],\n",
        "             marker='o', label=region, alpha=0.8, linewidth=2, color='darkblue')\n",
        "    ax.fill_between(region_data['year_start'],\n",
        "                    region_data['relative_change_pct'] - region_data['relative_change_error_pct'],\n",
        "                    region_data['relative_change_pct'] + region_data['relative_change_error_pct'],\n",
        "                    alpha=0.2, color='darkblue')\n",
        "ax.set_xlabel('Year', fontsize=12)\n",
        "ax.set_ylabel('Relative Mass Change (%)', fontsize=12)\n",
        "ax.set_title('Global Annual Relative Glacier Mass Change', fontsize=14)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_rel / 'global_relative_change_plot.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "relative_result = mk.original_test(region_data['relative_change_pct'])\n",
        "print(relative_result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for region in all_regions:\n",
        "    region_data = results_df[results_df['region'] == region].sort_values('year_start')\n",
        "    absolute_result = mk.original_test(region_data['relative_change_pct'])\n",
        "    print(f\"{region}: {absolute_result}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Absolute change for comparison\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "all_regions = sorted(results_df['region'].unique())\n",
        "global_regions = [r for r in all_regions if r.lower() == 'global']\n",
        "for region in global_regions:\n",
        "    region_data = results_df[results_df['region'] == region].sort_values('year_start')\n",
        "    ax.plot(region_data['year_start'], region_data['annual_change_gt'],\n",
        "             marker='o', label=region, alpha=0.8, linewidth=2, color='darkblue')\n",
        "    ax.fill_between(region_data['year_start'],\n",
        "                    region_data['annual_change_gt'] - region_data['annual_change_error'],\n",
        "                    region_data['annual_change_gt'] + region_data['annual_change_error'],\n",
        "                    alpha=0.2, color='darkblue')\n",
        "ax.set_xlabel('Year', fontsize=12)\n",
        "ax.set_ylabel('Mass Change (Gt)', fontsize=12)\n",
        "ax.set_title('Global Annual Absolute Glacier Mass Change', fontsize=14)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_rel / 'global_absolute_change_plot.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for region in all_regions:\n",
        "    region_data = results_df[results_df['region'] == region].sort_values('year_start')\n",
        "    absolute_result = mk.original_test(region_data['annual_change_gt'])\n",
        "    print(f\"{region}: {absolute_result}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "for region in global_regions:\n",
        "    region_data = results_df[results_df['region'] == region].sort_values('year_start')\n",
        "    ax.scatter(region_data['annual_change_gt'], region_data['relative_change_pct'],\n",
        "               marker='o', label=region, alpha=0.8, s=50, color='darkblue')\n",
        "ax.set_xlabel('Absolute Change (Gt)', fontsize=12)\n",
        "ax.set_ylabel('Relative Change (%)', fontsize=12)\n",
        "ax.set_title('Absolute vs Relative Change (Global)', fontsize=14)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
        "ax.axvline(x=0, color='k', linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_rel / 'absolute_vs_relative_change.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "246042a0",
      "metadata": {},
      "outputs": [],
      "source": [
        "global_data = results_df[results_df['region'] == 'Global'].sort_values('year_start')\n",
        "x = global_data['year_start'].values.astype(float)\n",
        "y = global_data['relative_change_pct'].values\n",
        "sigma = global_data['relative_change_error_pct'].values\n",
        "w = 1.0 / (sigma**2)\n",
        "X_lin  = sm.add_constant(x)\n",
        "X_quad = sm.add_constant(np.column_stack([x, x**2]))\n",
        "m_lin  = sm.WLS(y, X_lin,  weights=w).fit()\n",
        "m_quad = sm.WLS(y, X_quad, weights=w).fit()\n",
        "print(\"AIC linear:\", m_lin.aic)\n",
        "print(\"AIC quad  :\", m_quad.aic)\n",
        "print(\"quad term (t^2) coef, p:\", m_quad.params[2], m_quad.pvalues[2])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfc2b1d9",
      "metadata": {},
      "outputs": [],
      "source": [
        "global_data = results_df[results_df['region'] == 'Global'].sort_values('year_start')\n",
        "x = global_data['year_start'].values.astype(float)\n",
        "y = global_data['annual_change_gt'].values\n",
        "sigma = global_data['annual_change_error'].values\n",
        "w = 1.0 / (sigma**2)\n",
        "X_lin  = sm.add_constant(x)\n",
        "X_quad = sm.add_constant(np.column_stack([x, x**2]))\n",
        "m_lin  = sm.WLS(y, X_lin,  weights=w).fit()\n",
        "m_quad = sm.WLS(y, X_quad, weights=w).fit()\n",
        "print(\"AIC linear:\", m_lin.aic)\n",
        "print(\"AIC quad  :\", m_quad.aic)\n",
        "print(\"quad term (t^2) coef, p:\", m_quad.params[2], m_quad.pvalues[2])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce42dd0a",
      "metadata": {},
      "source": [
        "### Combined absolute and relative change plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_regions = sorted(results_df['region'].unique())\n",
        "for region in all_regions:\n",
        "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
        "    region_data = results_df[results_df['region'] == region].sort_values('year_start')\n",
        "\n",
        "    # Compute relative change from start to end\n",
        "    start_mass = region_data.iloc[0]['glacier_mass_at_start']\n",
        "    end_mass = region_data.iloc[-1]['glacier_mass_at_start']\n",
        "    relative_change = ((end_mass - start_mass) / start_mass) * 100\n",
        "\n",
        "    # Plot relative change\n",
        "    ax1.plot(region_data['year_start'], region_data['relative_change_pct'],\n",
        "             marker='o', label='Relative Change', alpha=0.8, linewidth=2, color='darkblue')\n",
        "    ax1.fill_between(region_data['year_start'],\n",
        "                    region_data['relative_change_pct'] - region_data['relative_change_error_pct'],\n",
        "                    region_data['relative_change_pct'] + region_data['relative_change_error_pct'],\n",
        "                    alpha=0.2, color='darkblue')\n",
        "    ax1.set_xlabel('Year', fontsize=12)\n",
        "    ax1.set_ylabel('Relative Mass Change (%)', fontsize=12)\n",
        "    ax1.set_title(f'{region} - Glacier Mass Change', fontsize=14)\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # Create a twin axis for absolute change\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.plot(region_data['year_start'], region_data['annual_change_gt'],\n",
        "             marker='s', label='Absolute Change', alpha=0.8, linewidth=2, color='crimson')\n",
        "    ax2.fill_between(region_data['year_start'],\n",
        "                    region_data['annual_change_gt'] - region_data['annual_change_error'],\n",
        "                    region_data['annual_change_gt'] + region_data['annual_change_error'],\n",
        "                    alpha=0.2, color='crimson')\n",
        "    ax2.set_ylabel('Mass Change (Gt)', fontsize=12)\n",
        "\n",
        "    # Find the max absolute values for both axes\n",
        "    max_rel = max(abs(region_data['relative_change_pct'].min()), abs(region_data['relative_change_pct'].max()))\n",
        "    max_abs = max(abs(region_data['annual_change_gt'].min()), abs(region_data['annual_change_gt'].max()))\n",
        "\n",
        "    # Set y-limits to be symmetric around zero\n",
        "    ax1.set_ylim(-max_rel * 1.55, max_rel * 1.4)\n",
        "    ax2.set_ylim(-max_abs * 1.55, max_abs * 1.4)\n",
        "\n",
        "    # Draw zero lines\n",
        "    ax1.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
        "    ax2.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
        "\n",
        "    # Combine legends from both axes\n",
        "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
        "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
        "    ax1.legend(lines1 + lines2, labels1 + labels2, loc='lower left')\n",
        "\n",
        "    # Add annotation for total relative change\n",
        "    ax1.text(0.81, 0.98, f'Total Change: {relative_change:.2f}%',\n",
        "             transform=ax1.transAxes, verticalalignment='top', fontsize=10,\n",
        "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    #plt.savefig(output_rel / f'{region}_combined_change.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "for region in global_regions:\n",
        "    region_data = results_df[results_df['region'] == region].sort_values('year_start')\n",
        "    ax.plot(region_data['year_start'], region_data['glacier_mass_at_start'],\n",
        "             marker='s', label=region, alpha=0.8, linewidth=2, color='darkblue')\n",
        "    ax.fill_between(region_data['year_start'],\n",
        "                    region_data['glacier_mass_at_start'] - region_data['glacier_mass_error_at_start'],\n",
        "                    region_data['glacier_mass_at_start'] + region_data['glacier_mass_error_at_start'],\n",
        "                    alpha=0.2, color='darkblue')\n",
        "ax.set_xlabel('Year', fontsize=12)\n",
        "ax.set_ylabel('Glacier Mass (Gt)', fontsize=12)\n",
        "ax.set_title('Global Glacier Mass', fontsize=14)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_ylim(bottom=0)\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_rel / 'global_glacier_mass_plot.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76b8fbdd",
      "metadata": {},
      "source": [
        "### Relative changes per region"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for region in sorted(results_df['region'].unique()):\n",
        "    region_data = results_df[results_df['region'] == region].sort_values('year_start')\n",
        "    x = region_data['year_start'].values\n",
        "    y = region_data['relative_change_pct'].values\n",
        "    y_err = region_data['relative_change_error_pct'].values\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 4))\n",
        "    ax.plot(x, y, marker='o', linestyle='-', color='darkblue', alpha=0.6)\n",
        "    ax.fill_between(x, y - y_err, y + y_err, color='darkblue', alpha=0.15)\n",
        "    y_lower_r = np.nanmin(y - y_err)\n",
        "    y_upper_r = np.nanmax(y + y_err)\n",
        "    pad_r = 0.05 * (y_upper_r - y_lower_r) if y_upper_r > y_lower_r else 1.0\n",
        "    \n",
        "    ax.set_ylim(y_lower_r - pad_r, y_upper_r + pad_r)\n",
        "    ax.set_title(f'{region}  Annual Relative Glacier Mass Change (%)')\n",
        "    ax.set_xlabel('Year Start')\n",
        "    ax.set_ylabel('Relative Change (%)')\n",
        "    ax.grid(alpha=0.3)\n",
        "    \n",
        "    fname = f\"relative_change_{region.replace(' ', '_').replace('/', '_').lower()}.png\"\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_rel / fname, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a205f7ad",
      "metadata": {},
      "source": [
        "### Mass evolution per region"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "093af117",
      "metadata": {},
      "outputs": [],
      "source": [
        "for region in sorted(results_df['region'].unique()):\n",
        "    region_data = results_df[results_df['region'] == region].sort_values('year_start')\n",
        "    x = region_data['year_start'].values\n",
        "    y = region_data['glacier_mass_at_start'].values\n",
        "    y_err = region_data['glacier_mass_error_at_start'].values\n",
        "\n",
        "    # Compute relative change from start to end\n",
        "    start_mass = region_data.iloc[0]['glacier_mass_at_start']\n",
        "    end_mass = region_data.iloc[-1]['glacier_mass_at_start']\n",
        "    relative_change = ((end_mass - start_mass) / start_mass) * 100\n",
        "\n",
        "    # Create the plot\n",
        "    fig, ax = plt.subplots(figsize=(10, 4))\n",
        "    ax.plot(x, y, marker='s', linestyle='-', alpha=0.8, linewidth=2, color='darkblue')\n",
        "    ax.fill_between(x, y - y_err, y + y_err, alpha=0.15, color='darkblue')\n",
        "\n",
        "    # Set y-axis limits with padding\n",
        "    y_lower_r = np.nanmin(y - y_err)\n",
        "    y_upper_r = np.nanmax(y + y_err)\n",
        "    pad_r = 0.05 * (y_upper_r - y_lower_r) if y_upper_r > y_lower_r else 1.0\n",
        "    ax.set_ylim(y_lower_r - pad_r, y_upper_r + pad_r)\n",
        "\n",
        "    # Add relative change as text\n",
        "    ax.text(\n",
        "        0.8, 0.95,\n",
        "        f\"Relative Change: {relative_change:.1f}%\",\n",
        "        transform=ax.transAxes,\n",
        "        fontsize=10,\n",
        "        verticalalignment='top',\n",
        "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8)\n",
        "    )\n",
        "\n",
        "    ax.set_title(f'{region}  Glacier Mass (Gt)')\n",
        "    ax.set_xlabel('Year Start')\n",
        "    ax.set_ylabel('Glacier Mass (Gt)')\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "    # Save the figure\n",
        "    fname = f\"glacier_mass_{region.replace(' ', '_').replace('/', '_').lower()}.png\"\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_rel / fname, dpi=300, bbox_inches='tight')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d909a25c",
      "metadata": {},
      "source": [
        "### Combined relative change and mass evolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df91b822",
      "metadata": {},
      "outputs": [],
      "source": [
        "for region in sorted(results_df['region'].unique()):\n",
        "    region_data = results_df[results_df['region'] == region].sort_values('year_start')\n",
        "\n",
        "    # Glacier Mass Data\n",
        "    x_mass = region_data['year_start'].values\n",
        "    y_mass = region_data['glacier_mass_at_start'].values\n",
        "    y_err_mass = region_data['glacier_mass_error_at_start'].values\n",
        "\n",
        "    # Relative Change Data\n",
        "    x_rel = region_data['year_start'].values\n",
        "    y_rel = region_data['relative_change_pct'].values\n",
        "    y_err_rel = region_data['relative_change_error_pct'].values\n",
        "\n",
        "    # Compute relative change from start to end for glacier mass\n",
        "    start_mass = region_data.iloc[0]['glacier_mass_at_start']\n",
        "    end_mass = region_data.iloc[-1]['glacier_mass_at_start']\n",
        "    relative_change = ((end_mass - start_mass) / start_mass) * 100\n",
        "\n",
        "    # Create a figure with two subplots\n",
        "    fig, (ax2, ax1) = plt.subplots(nrows=2, figsize=(10, 8), sharex=True)\n",
        "\n",
        "    # --- Glacier Mass Subplot ---\n",
        "    ax1.plot(x_mass, y_mass, marker='s', linestyle='-', alpha=0.8, linewidth=2, color='darkblue')\n",
        "    ax1.fill_between(x_mass, y_mass - y_err_mass, y_mass + y_err_mass, alpha=0.15, color='darkblue')\n",
        "\n",
        "    # Set y-axis limits with padding\n",
        "    y_lower_mass = np.nanmin(y_mass - y_err_mass)\n",
        "    y_upper_mass = np.nanmax(y_mass + y_err_mass)\n",
        "    pad_mass = 0.05 * (y_upper_mass - y_lower_mass) if y_upper_mass > y_lower_mass else 1.0\n",
        "    ax1.set_ylim(y_lower_mass - pad_mass, y_upper_mass + pad_mass)\n",
        "\n",
        "    # Add relative change as text\n",
        "    ax1.text(\n",
        "        0.8, 0.95,\n",
        "        f\"Relative Change: {relative_change:.1f}%\",\n",
        "        transform=ax1.transAxes,\n",
        "        fontsize=10,\n",
        "        verticalalignment='top',\n",
        "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8)\n",
        "    )\n",
        "\n",
        "    # ax1.set_title(f'{region}  Glacier Mass (Gt)')\n",
        "    ax1.set_ylabel('Glacier Mass (Gt)')\n",
        "    ax1.grid(alpha=0.3)\n",
        "\n",
        "    # Annual Relative Change Subplot\n",
        "    ax2.plot(x_rel, y_rel, marker='o', linestyle='-', color='darkblue', alpha=0.6)\n",
        "    ax2.fill_between(x_rel, y_rel - y_err_rel, y_rel + y_err_rel, color='darkblue', alpha=0.15)\n",
        "\n",
        "    # Set y-axis limits with padding\n",
        "    y_lower_rel = np.nanmin(y_rel - y_err_rel)\n",
        "    y_upper_rel = np.nanmax(y_rel + y_err_rel)\n",
        "    pad_rel = 0.05 * (y_upper_rel - y_lower_rel) if y_upper_rel > y_lower_rel else 1.0\n",
        "    ax2.set_ylim(y_lower_rel - pad_rel, y_upper_rel + pad_rel)\n",
        "\n",
        "    ax2.set_title(f'{region}')\n",
        "    ax1.set_xlabel('Year')\n",
        "    ax2.set_ylabel('Relative Annual Change (%)')\n",
        "    ax2.grid(alpha=0.3)\n",
        "\n",
        "    # Save the figure\n",
        "    fname = f\"combined_{region.replace(' ', '_').replace('/', '_').lower()}.png\"\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_rel / fname, dpi=300, bbox_inches='tight')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trend_results = []\n",
        "for region in sorted(results_df['region'].unique()):\n",
        "    region_data = results_df[results_df['region'] == region].sort_values('year_start')\n",
        "    x = region_data['year_start'].values\n",
        "    y = region_data['relative_change_pct'].values\n",
        "    slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
        "    trend_per_year_pct = slope\n",
        "    is_significant = p_value < 0.05\n",
        "    trend_direction = 'increasing' if slope > 0 else 'decreasing'\n",
        "    trend_results.append({\n",
        "        'region': region,\n",
        "        'slope_pct_per_year': round(trend_per_year_pct, 4),\n",
        "        'intercept': round(intercept, 2),\n",
        "        'r_squared': round(r_value**2, 4),\n",
        "        'p_value': round(p_value, 4),\n",
        "        'std_err': round(std_err, 4),\n",
        "        'is_significant': is_significant,\n",
        "        'trend_direction': trend_direction\n",
        "    })\n",
        "trend_df = pd.DataFrame(trend_results)\n",
        "print(trend_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export results to CSV\n",
        "# output_csv = output_rel / 'annual_relative_change_results.csv'\n",
        "# results_df.to_csv(output_csv, index=False)\n",
        "# print(f\"Results exported to: {output_csv}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization of glambie runs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Global\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "csv_files = sorted(glambie_runs.glob(\"Reanalysis*/0_*/consensus/csvs/global_mwe.csv\"))\n",
        "plt.figure(figsize=(14, 8))\n",
        "for csv_file in csv_files:\n",
        "    df = pd.read_csv(str(csv_file))\n",
        "    date_col = next((c for c in df.columns if 'date' in c.lower()), df.columns[0])\n",
        "    change_col = next((c for c in df.columns if 'change' in c.lower()), None)\n",
        "    error_col = next((c for c in df.columns if 'error' in c.lower()), None)\n",
        "    if change_col and error_col:\n",
        "        path_parts = csv_file.parts\n",
        "        label = next((part for part in path_parts if part.startswith('Reanalysis')), 'Unknown')\n",
        "        plt.errorbar(df[date_col], df[change_col], yerr=df[error_col],\n",
        "                        label=label, fmt='.-', capsize=3, alpha=0.7)\n",
        "\n",
        "plt.title('Global Mass Change - Reanalysis Consensus')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Mass Change (Gt)')\n",
        "plt.legend(bbox_to_anchor=(0.63, 1), loc='upper left')\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(1, 19):\n",
        "    csv_files = sorted(glambie_runs.glob(f\"Reanalysis*/{i}_*/consensus/csvs/consensus_calendar_year_gt*.csv\"))\n",
        "    region_matches = list(glambie_runs.glob(f\"Reanalysis*/{i}_*\"))\n",
        "    region_name = 'Unknown'\n",
        "    if region_matches:\n",
        "        folder_name = region_matches[0].name\n",
        "        region_name = folder_name.split('_', 1)[1] if '_' in folder_name else folder_name\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    for csv_file in csv_files:\n",
        "        df = pd.read_csv(str(csv_file))\n",
        "        date_col = next((c for c in df.columns if 'date' in c.lower()), df.columns[0])\n",
        "        change_col = next((c for c in df.columns if 'change' in c.lower()), None)\n",
        "        error_col = next((c for c in df.columns if 'error' in c.lower()), None)\n",
        "        if change_col and error_col:\n",
        "            path_parts = csv_file.parts\n",
        "            label = next((part for part in path_parts if part.startswith('Reanalysis')), 'Unknown')\n",
        "            plt.errorbar(df[date_col], df[change_col], yerr=df[error_col],\n",
        "                        label=label, fmt='.-', capsize=3, alpha=0.7)\n",
        "    plt.title(f'Mass Change - {region_name.title()} Region')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Mass Change (Gt)')\n",
        "    plt.legend(bbox_to_anchor=(0.63, 1), loc='upper left')\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "glambie",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
