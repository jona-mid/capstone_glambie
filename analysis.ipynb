{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Glambie anaylsis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d52907f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import glob\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "from scipy import stats\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "import pymannkendall as mk\n",
        "import warnings\n",
        "import geopandas as gpd\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# Paths\n",
        "input_dir = Path(\"input\")\n",
        "output_dir = Path(\"output\")\n",
        "input_rel = input_dir / \"glambie_reference\"\n",
        "input_maps = input_dir / \"maps\"\n",
        "input_datasets = input_dir / \"input_datasets\"\n",
        "glambie_runs = input_dir / \"glambie_runs\"\n",
        "output_sensitivity = output_dir / \"sensitivity\"\n",
        "output_rel = output_dir / \"relative_change\"\n",
        "output_dir_datasets = output_dir / \"datasets\"\n",
        "\n",
        "# Set colors\n",
        "colors_list = sns.color_palette(palette='colorblind', n_colors=18, desat=0.9)\n",
        "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=colors_list)\n",
        "# two colors (first two from seaborn colorblind)\n",
        "blue, orange = colors_list[:2]   # first two colors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2df31361",
      "metadata": {},
      "source": [
        "## Relative change calculations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8673438",
      "metadata": {},
      "outputs": [],
      "source": [
        "glacier_mass_2000_path = input_rel / \"glacier_mass_2000.csv\"\n",
        "calendar_years_path = input_rel / \"calendar_years\"\n",
        "\n",
        "mass_2000 = pd.read_csv(str(glacier_mass_2000_path), sep=';')\n",
        "file_to_mass_data = {}\n",
        "for _, row in mass_2000.iterrows():\n",
        "    file_to_mass_data[row['File']] = {\n",
        "        'region': row['Region'],\n",
        "        'mass': row['Mass'],\n",
        "        'error': row['Error']\n",
        "    }\n",
        "annual_changes = {}\n",
        "\n",
        "for csv_file in sorted(glob.glob(str(calendar_years_path / \"*.csv\"))):\n",
        "    annual_changes[Path(csv_file).name] = pd.read_csv(csv_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "711b1092",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate annual relative change with uncertainty propagation\n",
        "results = []\n",
        "\n",
        "for filename, df_changes in sorted(annual_changes.items()):\n",
        "    matched_mass_data = file_to_mass_data[filename]\n",
        "    current_mass = matched_mass_data['mass']\n",
        "    current_mass_error = matched_mass_data['error']\n",
        "\n",
        "    df_changes_sorted = df_changes.sort_values('start_dates').reset_index(drop=True)\n",
        "\n",
        "    for idx, row in df_changes_sorted.iterrows():\n",
        "        annual_change = row['combined_gt']\n",
        "        annual_change_error = row['combined_gt_errors']\n",
        "\n",
        "        relative_change = annual_change / current_mass\n",
        "\n",
        "        # error propagation\n",
        "        relative_change_error_term1 = (annual_change_error / annual_change) ** 2\n",
        "        relative_change_error_term2 = (current_mass_error / current_mass) ** 2\n",
        "        relative_change_error = abs(relative_change) * np.sqrt(relative_change_error_term1 + relative_change_error_term2)\n",
        "\n",
        "        results.append({\n",
        "            'region': matched_mass_data['region'],\n",
        "            'year_start': int(row['start_dates']),\n",
        "            'year_end': int(row['end_dates']),\n",
        "            'glacier_mass_at_start': current_mass,\n",
        "            'glacier_mass_error_at_start': current_mass_error,\n",
        "            'annual_change_gt': annual_change,\n",
        "            'annual_change_error': annual_change_error,\n",
        "            'relative_change': relative_change,\n",
        "            'relative_change_error': relative_change_error,\n",
        "            'relative_change_pct': relative_change * 100,\n",
        "            'relative_change_error_pct': relative_change_error * 100\n",
        "        })\n",
        "\n",
        "        current_mass = current_mass + annual_change\n",
        "        current_mass_error = np.sqrt(current_mass_error**2 + annual_change_error**2)\n",
        "\n",
        "results_df = pd.DataFrame(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54ea7535",
      "metadata": {},
      "source": [
        "### Combined relative change and mass evolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc5c2236",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "all_regions = sorted(results_df['region'].unique())\n",
        "global_regions = [r for r in all_regions if r.lower() == 'global']\n",
        "other_regions = [r for r in all_regions if r.lower() != 'global']\n",
        "\n",
        "ax1 = axes[0]\n",
        "for region in global_regions:\n",
        "    region_data = results_df[results_df['region'] == region].sort_values('year_start')\n",
        "    ax1.plot(region_data['year_start'], region_data['relative_change_pct'],\n",
        "             marker='o', label=region, alpha=0.8, linewidth=2, color=blue)\n",
        "    ax1.fill_between(region_data['year_start'],\n",
        "                      region_data['relative_change_pct'] - region_data['relative_change_error_pct'],\n",
        "                      region_data['relative_change_pct'] + region_data['relative_change_error_pct'],\n",
        "                      alpha=0.2, color=blue)\n",
        "ax1.set_xlabel('Year Start', fontsize=12)\n",
        "ax1.set_ylabel('Relative Change (%)', fontsize=12)\n",
        "ax1.set_title('Global Annual Relative Glacier Mass Change', fontsize=14)\n",
        "ax1.legend(fontsize=10, loc='lower left')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
        "\n",
        "ax2 = axes[1]\n",
        "for region in other_regions:\n",
        "    region_data = results_df[results_df['region'] == region].sort_values('year_start')\n",
        "    ax2.plot(region_data['year_start'], region_data['relative_change_pct'],\n",
        "             marker='o', label=region, alpha=0.8, linewidth=2)\n",
        "    ax2.fill_between(region_data['year_start'],\n",
        "                      region_data['relative_change_pct'] - region_data['relative_change_error_pct'],\n",
        "                      region_data['relative_change_pct'] + region_data['relative_change_error_pct'],\n",
        "                      alpha=0.15)\n",
        "ax2.set_xlabel('Year Start', fontsize=12)\n",
        "ax2.set_ylabel('Relative Change (%)', fontsize=12)\n",
        "ax2.set_title('Regional Annual Relative Glacier Mass Change', fontsize=14)\n",
        "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_rel / 'relative_change_plots.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4b57316",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "ax3 = axes[0]\n",
        "\n",
        "for region in global_regions:\n",
        "    region_data = results_df[results_df['region'] == region].sort_values('year_start')\n",
        "    ax3.plot(region_data['year_start'], region_data['glacier_mass_at_start'],\n",
        "             marker='s', label=region, alpha=0.8, linewidth=2, color=blue)\n",
        "    ax3.fill_between(region_data['year_start'],\n",
        "                      region_data['glacier_mass_at_start'] - region_data['glacier_mass_error_at_start'],\n",
        "                      region_data['glacier_mass_at_start'] + region_data['glacier_mass_error_at_start'],\n",
        "                      alpha=0.2, color=blue)\n",
        "ax3.set_xlabel('Year Start', fontsize=12)\n",
        "ax3.set_ylabel('Glacier Mass (Gt)', fontsize=12)\n",
        "ax3.set_title('Global Glacier Mass', fontsize=14)\n",
        "ax3.legend(fontsize=10)\n",
        "ax3.grid(True, alpha=0.3)\n",
        "ax3.set_ylim(bottom=0)\n",
        "ax4 = axes[1]\n",
        "\n",
        "for region in other_regions:\n",
        "    region_data = results_df[results_df['region'] == region].sort_values('year_start')\n",
        "    ax4.plot(region_data['year_start'], region_data['glacier_mass_at_start'],\n",
        "             marker='s', label=region, alpha=0.8, linewidth=2)\n",
        "    ax4.fill_between(region_data['year_start'],\n",
        "                      region_data['glacier_mass_at_start'] - region_data['glacier_mass_error_at_start'],\n",
        "                      region_data['glacier_mass_at_start'] + region_data['glacier_mass_error_at_start'],\n",
        "                      alpha=0.15)\n",
        "ax4.set_xlabel('Year Start', fontsize=12)\n",
        "ax4.set_ylabel('Glacier Mass (Gt)', fontsize=12)\n",
        "ax4.set_title('Regional Glacier Mass', fontsize=14)\n",
        "ax4.legend(bbox_to_anchor=(1, 0.8), loc='upper left', fontsize=9)\n",
        "ax4.grid(True, alpha=0.3)\n",
        "ax4.set_ylim(bottom=0)\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_rel / 'glacier_mass_evolution.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a65656c9",
      "metadata": {},
      "source": [
        "### Relative vs absolute change with trend test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b7f18be",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "all_regions = sorted(results_df['region'].unique())\n",
        "global_regions = [r for r in all_regions if r.lower() == 'global']\n",
        "for region in global_regions:\n",
        "    region_data = results_df[results_df['region'] == region].sort_values('year_start')\n",
        "    ax.plot(region_data['year_start'], region_data['relative_change_pct'],\n",
        "             marker='o', label=region, alpha=0.8, linewidth=2, color=blue)\n",
        "    ax.fill_between(region_data['year_start'],\n",
        "                    region_data['relative_change_pct'] - region_data['relative_change_error_pct'],\n",
        "                    region_data['relative_change_pct'] + region_data['relative_change_error_pct'],\n",
        "                    alpha=0.2, color=blue)\n",
        "ax.set_xlabel('Year', fontsize=12)\n",
        "ax.set_ylabel('Relative Mass Change (%)', fontsize=12)\n",
        "ax.set_title('Global Annual Relative Glacier Mass Change', fontsize=14)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_rel / 'global_relative_change_plot.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db4f3c55",
      "metadata": {},
      "outputs": [],
      "source": [
        "for region in all_regions:\n",
        "    region_data = results_df[results_df['region'] == region].sort_values('year_start')\n",
        "    absolute_result = mk.original_test(region_data['relative_change_pct'])\n",
        "    print(f\"{region}: {absolute_result}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33a12875",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Absolute change for comparison\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "all_regions = sorted(results_df['region'].unique())\n",
        "global_regions = [r for r in all_regions if r.lower() == 'global']\n",
        "for region in global_regions:\n",
        "    region_data = results_df[results_df['region'] == region].sort_values('year_start')\n",
        "    ax.plot(region_data['year_start'], region_data['annual_change_gt'],\n",
        "             marker='o', label=region, alpha=0.8, linewidth=2, color=blue)\n",
        "    ax.fill_between(region_data['year_start'],\n",
        "                    region_data['annual_change_gt'] - region_data['annual_change_error'],\n",
        "                    region_data['annual_change_gt'] + region_data['annual_change_error'],\n",
        "                    alpha=0.2, color=blue)\n",
        "ax.set_xlabel('Year', fontsize=12)\n",
        "ax.set_ylabel('Mass Change (Gt)', fontsize=12)\n",
        "ax.set_title('Global Annual Absolute Glacier Mass Change', fontsize=14)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_rel / 'global_absolute_change_plot.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ca15a5d",
      "metadata": {},
      "outputs": [],
      "source": [
        "for region in all_regions:\n",
        "    region_data = results_df[results_df['region'] == region].sort_values('year_start')\n",
        "    absolute_result = mk.original_test(region_data['annual_change_gt'])\n",
        "    print(f\"{region}: {absolute_result}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b33479b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "for region in global_regions:\n",
        "    region_data = results_df[results_df['region'] == region].sort_values('year_start')\n",
        "    ax.scatter(region_data['annual_change_gt'], region_data['relative_change_pct'],\n",
        "               marker='o', label=region, alpha=0.8, s=50, color=blue)\n",
        "ax.set_xlabel('Absolute Change (Gt)', fontsize=12)\n",
        "ax.set_ylabel('Relative Change (%)', fontsize=12)\n",
        "ax.set_title('Absolute vs Relative Change (Global)', fontsize=14)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
        "ax.axvline(x=0, color='k', linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_rel / 'absolute_vs_relative_change.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d909a25c",
      "metadata": {},
      "source": [
        "### Combined relative change and mass evolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df91b822",
      "metadata": {},
      "outputs": [],
      "source": [
        "for region in sorted(results_df['region'].unique()):\n",
        "    region_data = results_df[results_df['region'] == region].sort_values('year_start')\n",
        "\n",
        "    # Glacier Mass Data\n",
        "    x_mass = region_data['year_start'].values\n",
        "    y_mass = region_data['glacier_mass_at_start'].values\n",
        "    y_err_mass = region_data['glacier_mass_error_at_start'].values\n",
        "\n",
        "    # Relative Change Data\n",
        "    x_rel = region_data['year_start'].values\n",
        "    y_rel = region_data['relative_change_pct'].values\n",
        "    y_err_rel = region_data['relative_change_error_pct'].values\n",
        "\n",
        "    # Compute relative change from start to end for glacier mass\n",
        "    start_mass = region_data.iloc[0]['glacier_mass_at_start']\n",
        "    end_mass = region_data.iloc[-1]['glacier_mass_at_start']\n",
        "    relative_change = ((end_mass - start_mass) / start_mass) * 100\n",
        "\n",
        "    # Create a figure with two subplots (top = upper, bottom = glacier mass)\n",
        "    fig, (ax_top, ax_bottom) = plt.subplots(nrows=2, figsize=(10, 8), sharex=True)\n",
        "\n",
        "    # Upper subplot: Relative change (%) + twin for Absolute change (Gt)\n",
        "    ax_top.plot(x_rel, y_rel, marker='o', label='Relative Change', alpha=0.8, linewidth=2, color=blue)\n",
        "    ax_top.fill_between(x_rel, y_rel - y_err_rel, y_rel + y_err_rel, alpha=0.1, color=blue)\n",
        "    ax_top.set_ylabel('Relative Mass Change (%)', fontsize=12)\n",
        "    ax_top.set_title(f'{region}')\n",
        "    ax_top.grid(True, alpha=0.3)\n",
        "\n",
        "    # Twin axis for absolute change (Gt) # DELETE IF PLOTTING ONLY RELATIVE CHANGES\n",
        "    ax_top_twin = ax_top.twinx()\n",
        "    ax_top_twin.plot(region_data['year_start'], region_data['annual_change_gt'],\n",
        "                     marker='s', label='Absolute Change', alpha=0.6, linewidth=2, color=orange)\n",
        "    ax_top_twin.fill_between(region_data['year_start'],\n",
        "                             region_data['annual_change_gt'] - region_data['annual_change_error'],\n",
        "                             region_data['annual_change_gt'] + region_data['annual_change_error'],\n",
        "                             alpha=0.1, color=orange)\n",
        "    ax_top_twin.set_ylabel('Mass Change (Gt)', fontsize=12)\n",
        "\n",
        "    # Symmetric y-limits and zero lines for upper panel\n",
        "    max_rel = max(abs(region_data['relative_change_pct'].min()), abs(region_data['relative_change_pct'].max()))\n",
        "    max_abs = max(abs(region_data['annual_change_gt'].min()), abs(region_data['annual_change_gt'].max()))\n",
        "    ax_top.set_ylim(-max_rel * 1.55, max_rel * 1.4)\n",
        "    ax_top_twin.set_ylim(-max_abs * 1.55, max_abs * 1.4)\n",
        "    ax_top.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
        "    ax_top_twin.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
        "\n",
        "    # Lower subplot: Glacier Mass (Gt)\n",
        "    ax_bottom.plot(x_mass, y_mass, marker='s', linestyle='-', alpha=0.8, linewidth=2, color=blue)\n",
        "    ax_bottom.fill_between(x_mass, y_mass - y_err_mass, y_mass + y_err_mass, alpha=0.15, color=blue)\n",
        "    y_lower_mass = np.nanmin(y_mass - y_err_mass)\n",
        "    y_upper_mass = np.nanmax(y_mass + y_err_mass)\n",
        "    pad_mass = 0.05 * (y_upper_mass - y_lower_mass) if y_upper_mass > y_lower_mass else 1.0\n",
        "    ax_bottom.set_ylim(y_lower_mass - pad_mass, y_upper_mass + pad_mass)\n",
        "    ax_bottom.text(0.78, 0.95, f\"Relative Change: {relative_change:.1f}%\",\n",
        "                   transform=ax_bottom.transAxes, fontsize=10, verticalalignment='top',\n",
        "                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "    ax_bottom.set_ylabel('Glacier Mass (Gt)')\n",
        "    ax_bottom.set_xlabel('Year')\n",
        "    ax_bottom.grid(alpha=0.3)\n",
        "\n",
        "    fname = f\"combined_{region.replace(' ', '_').replace('/', '_').lower()}.png\"\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_rel / fname, dpi=300, bbox_inches='tight')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "939e8642",
      "metadata": {},
      "source": [
        "## Visualization of glambie runs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5b7f18a",
      "metadata": {},
      "source": [
        "Global\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33ceaf77",
      "metadata": {},
      "outputs": [],
      "source": [
        "csv_files = sorted(\n",
        "    list(glambie_runs.glob(\"datasets_including_most/0_*/consensus/csvs/global_gt.csv\"))\n",
        "    + list(glambie_runs.glob(\"datasets_default*/0_*/consensus/csvs/global_gt.csv\"))\n",
        ")\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "colors_list = list(plt.colormaps[\"tab10\"].colors)\n",
        "\n",
        "for file_idx, csv_file in enumerate(csv_files):\n",
        "    df = pd.read_csv(str(csv_file))\n",
        "    c = colors_list[file_idx % len(colors_list)]\n",
        "    label = csv_file.parents[3].name.split(\"_\", 1)[1]\n",
        "\n",
        "    ax.fill_between(\n",
        "        df[\"start_dates\"],\n",
        "        df[\"changes\"] - df[\"errors\"],\n",
        "        df[\"changes\"] + df[\"errors\"],\n",
        "        color=c, alpha=0.25\n",
        "    ) \n",
        "\n",
        "    ax.plot(df[\"start_dates\"], df[\"changes\"], color=c, linewidth=2, alpha=0.9, label=label)\n",
        "\n",
        "ax.set_xlabel(\"Year\", fontsize=14)\n",
        "ax.set_ylabel(\"Mass Change (Gt)\", fontsize=14)\n",
        "ax.legend(bbox_to_anchor=(0.78, 1), loc=\"upper left\", fontsize=16)\n",
        "ax.grid(True, alpha=0.8)\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7a11faa",
      "metadata": {},
      "source": [
        "Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7708a861",
      "metadata": {},
      "outputs": [],
      "source": [
        "for region_idx in range(1, 19):\n",
        "    csv_files = sorted(glambie_runs.glob(\n",
        "        f\"datasets_including*/{region_idx}_*/consensus/csvs/consensus_calendar_year_gt*.csv\"\n",
        "    ))\n",
        "    region_matches = list(glambie_runs.glob(f\"datasets_default*/{region_idx}_*\"))\n",
        "    region_name = region_matches[0].name.split(\"_\", 1)[1].replace('_', ' ').title()\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(14, 8))\n",
        "\n",
        "    ax.set_prop_cycle(color=plt.colormaps[\"tab20\"].colors)  # 20-color cycle\n",
        "\n",
        "    for file_idx, csv_file in enumerate(csv_files):\n",
        "        df = pd.read_csv(csv_file)\n",
        "        label = csv_file.parents[3].name.split(\"_\", 1)[1].replace('including_', '')\n",
        "\n",
        "        if \"errors\" in df.columns:\n",
        "            ax.errorbar(df[\"start_dates\"], df[\"changes\"], yerr=df[\"errors\"],\n",
        "                        fmt=\"o-\", capsize=5, alpha=0.6, linewidth=2, label=label)\n",
        "        else:\n",
        "            ax.plot(df[\"start_dates\"], df[\"changes\"], linewidth=2, alpha=0.6, label=label)\n",
        "\n",
        "    ax.set_title(region_name)\n",
        "    ax.set_xlabel(\"Date\", fontsize=12)\n",
        "    ax.set_ylabel(\"Mass Change (Gt)\", fontsize=12)\n",
        "    ax.legend(bbox_to_anchor=(0.78, 1), loc=\"upper left\")\n",
        "    ax.grid(True, linestyle=\"--\", alpha=0.6)\n",
        "    fig.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4338dba7",
      "metadata": {},
      "source": [
        "## Barcharts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e789a22",
      "metadata": {},
      "source": [
        "Comparison of different datasets in the algorithm. \n",
        "- Relative difference in overall mass change\n",
        "- Absolute difference in overall mass change\n",
        "- Spearman correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2514309",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Paths and configuration\n",
        "run1 = glambie_runs / \"Reanalysis_RGI_6_default\"\n",
        "run2 = glambie_runs / \"Reanalysis_RGI_6_including_most\"\n",
        "\n",
        "glacier_mass_file = input_rel / \"glacier_mass_2000.csv\"\n",
        "glacier_mass_df = pd.read_csv(str(glacier_mass_file), sep=\";\")\n",
        "glacier_mass_dict = dict(zip(glacier_mass_df[\"Region\"], glacier_mass_df[\"Mass\"]))\n",
        "\n",
        "# Region mappings\n",
        "regions_bar = {\n",
        "    \"1_alaska\": \"Alaska\",\n",
        "    \"2_western_canada_us\": \"W. Canada & US\",\n",
        "    \"3_arctic_canada_north\": \"Arctic Canada N.\",\n",
        "    \"4_arctic_canada_south\": \"Arctic Canada S.\",\n",
        "    \"5_greenland_periphery\": \"Greenland Per.\",\n",
        "    \"6_iceland\": \"Iceland\",\n",
        "    \"7_svalbard\": \"Svalbard\",\n",
        "    \"8_scandinavia\": \"Scandinavia\",\n",
        "    \"9_russian_arctic\": \"Russian Arctic\",\n",
        "    \"10_north_asia\": \"North Asia\",\n",
        "    \"11_central_europe\": \"Central Europe\",\n",
        "    \"12_caucasus_middle_east\": \"Caucasus & M.E.\",\n",
        "    \"13_central_asia\": \"Central Asia\",\n",
        "    \"14_south_asia_west\": \"South Asia W.\",\n",
        "    \"15_south_asia_east\": \"South Asia E.\",\n",
        "    \"16_low_latitudes\": \"Low Latitudes\",\n",
        "    \"17_southern_andes\": \"Southern Andes\",\n",
        "    \"18_new_zealand\": \"New Zealand\",\n",
        "    \"19_antarctic_and_subantarctic\": \"Antarctic & Sub.\",\n",
        "}\n",
        "\n",
        "mass_lookup = {\n",
        "    \"Alaska\": \"Alaska\",\n",
        "    \"W. Canada & US\": \"Western Canada and USA\",\n",
        "    \"Arctic Canada N.\": \"Arctic Canada north\",\n",
        "    \"Arctic Canada S.\": \"Arctic Canada south\",\n",
        "    \"Greenland Per.\": \"Greenland periphery\",\n",
        "    \"Iceland\": \"Iceland\",\n",
        "    \"Svalbard\": \"Svalbard and Jan Mayen\",\n",
        "    \"Scandinavia\": \"Scandinavia\",\n",
        "    \"Russian Arctic\": \"Russian Arctic\",\n",
        "    \"North Asia\": \"North Asia\",\n",
        "    \"Central Europe\": \"Central Europe\",\n",
        "    \"Caucasus & M.E.\": \"Caucasus and Middle East\",\n",
        "    \"Central Asia\": \"Central Asia\",\n",
        "    \"South Asia W.\": \"South Asia west\",\n",
        "    \"South Asia E.\": \"South Asia east\",\n",
        "    \"Low Latitudes\": \"Low latitudes\",\n",
        "    \"Southern Andes\": \"Southern Andes\",\n",
        "    \"New Zealand\": \"New Zealand\",\n",
        "    \"Antarctic & Sub.\": \"Antarctic and subantarctic islands\",\n",
        "    \"Global\": \"Global\",\n",
        "}\n",
        "\n",
        "def compute_all_metrics(df1, df2, glacier_mass):\n",
        "    merged = pd.merge(df1, df2, on=\"start_dates\", suffixes=(\"_run1\", \"_run2\"), how=\"outer\")\n",
        "    diff = merged[\"changes_run1\"] - merged[\"changes_run2\"]\n",
        "    cumul_run1 = merged[\"changes_run1\"].sum()\n",
        "    cumul_run2 = merged[\"changes_run2\"].sum()\n",
        "    if abs(cumul_run1) > 0.01:\n",
        "        rel_diff = (cumul_run2 - cumul_run1) / abs(cumul_run1) * 100.0\n",
        "    else:\n",
        "        rel_diff = 0.0\n",
        "    abs_diff = cumul_run2 - cumul_run1\n",
        "    rmse_pct = (rmse / glacier_mass * 100.0) if glacier_mass else 0.0\n",
        "    try:\n",
        "        corr, _ = spearmanr(merged[\"changes_run1\"], merged[\"changes_run2\"])\n",
        "        if np.isnan(corr):\n",
        "            corr = 0.0\n",
        "    except Exception:\n",
        "        corr = 0.0\n",
        "    return rel_diff, abs_diff, corr\n",
        "\n",
        "# Initialize lists to store metrics\n",
        "region_names = []\n",
        "rel_diff_values = []\n",
        "rmse_pct_values = []\n",
        "abs_diff_values = []\n",
        "corr_values = []  # New list for correlation values\n",
        "\n",
        "for region_dir, display_name in regions_bar.items():\n",
        "    region_key = \"_\".join(region_dir.split(\"_\")[1:])\n",
        "    csv1 = run1 / region_dir / \"consensus\" / \"csvs\" / f\"consensus_calendar_year_gt_{region_key}.csv\"\n",
        "    csv2 = run2 / region_dir / \"consensus\" / \"csvs\" / f\"consensus_calendar_year_gt_{region_key}.csv\"\n",
        "\n",
        "    df1 = pd.read_csv(str(csv1))\n",
        "    df2 = pd.read_csv(str(csv2))\n",
        "\n",
        "    mass_key = mass_lookup.get(display_name, display_name)\n",
        "    glacier_mass = glacier_mass_dict.get(mass_key, None)\n",
        "\n",
        "    rel_diff, abs_diff, corr = compute_all_metrics(df1, df2, glacier_mass)\n",
        "\n",
        "    region_names.append(display_name)\n",
        "    rel_diff_values.append(rel_diff)\n",
        "    rmse_pct_values.append(rmse_pct)\n",
        "    abs_diff_values.append(abs_diff)\n",
        "    corr_values.append(corr)\n",
        "\n",
        "# Compute metrics for the global data\n",
        "csv1_global = run1 / \"0_global\" / \"consensus\" / \"csvs\" / \"global_gt.csv\"\n",
        "csv2_global = run2 / \"0_global\" / \"consensus\" / \"csvs\" / \"global_gt.csv\"\n",
        "df1 = pd.read_csv(str(csv1_global))\n",
        "df2 = pd.read_csv(str(csv2_global))\n",
        "rel_diff, abs_diff, corr = compute_all_metrics(df1, df2, glacier_mass_dict.get(\"Global\", None))\n",
        "region_names.append(\"Global\")\n",
        "rel_diff_values.append(rel_diff)\n",
        "rmse_pct_values.append(rmse_pct)\n",
        "abs_diff_values.append(abs_diff)\n",
        "corr_values.append(corr)\n",
        "\n",
        "# Plotting\n",
        "fig, (ax3, ax4, ax5) = plt.subplots(1, 3, figsize=(18, 8), sharey=True)\n",
        "\n",
        "# Relative difference\n",
        "bars3 = ax3.barh(range(len(region_names)), rel_diff_values)\n",
        "ax3.set_yticks(range(len(region_names)))\n",
        "ax3.set_yticklabels(region_names)\n",
        "ax3.invert_yaxis()\n",
        "ax3.set_xlabel(\"Relative Change (%)\")\n",
        "ax3.set_title(\"Relative Mass Difference (negative = run shows more mass loss)\")\n",
        "ax3.axvline(0, color=\"black\", linewidth=0.8)\n",
        "max_abs_rel = max(abs(v) for v in rel_diff_values)\n",
        "for i, val in enumerate(rel_diff_values):\n",
        "    if val >= 0:\n",
        "        ax3.text(val + 0.02 * max_abs_rel, i, f\"+{val:.1f}%\", va=\"center\", fontsize=8)\n",
        "    else:\n",
        "        ax3.text(val - 0.02 * max_abs_rel, i, f\"{val:.1f}%\", va=\"center\", ha=\"right\", fontsize=8)\n",
        "pad = max_abs_rel * 0.15\n",
        "ax3.set_xlim(min(rel_diff_values) - pad, max(rel_diff_values) + pad)\n",
        "\n",
        "# Absolute difference\n",
        "bars4 = ax4.barh(range(len(region_names)), abs_diff_values)\n",
        "ax4.set_xlabel(\"Absolute Difference (Gt)\")\n",
        "ax4.set_title(\"Absolute Mass Difference\")\n",
        "ax4.axvline(0, color=\"black\", linewidth=0.8)\n",
        "max_abs_diff = max(abs(v) for v in abs_diff_values)\n",
        "for i, (val, rel) in enumerate(zip(abs_diff_values, rel_diff_values)):\n",
        "    if val >= 0:\n",
        "        ax4.text(val + 0.02 * max_abs_diff, i, f\"+{val:.2f}\", va=\"center\", fontsize=8)\n",
        "    else:\n",
        "        ax4.text(val - 0.02 * max_abs_diff, i, f\"{val:.2f}\", va=\"center\", ha=\"right\", fontsize=8)\n",
        "pad = max_abs_diff * 0.30\n",
        "ax4.set_xlim(min(abs_diff_values) - pad, max(abs_diff_values) + pad)\n",
        "\n",
        "# Correlation\n",
        "bars5 = ax5.barh(range(len(region_names)), corr_values)\n",
        "ax5.set_xlabel(\"Correlation\")\n",
        "ax5.set_title(\"Spearman Correlation\")\n",
        "ax5.set_xlim(-0.1, 1.1)\n",
        "for i, val in enumerate(corr_values):\n",
        "    if val >= 0:\n",
        "        ax5.text(val + 0.02, i, f\"{val:.2f}\", va=\"center\", fontsize=8)\n",
        "    else:\n",
        "        ax5.text(val + 0.08, i, f\"{val:.2f}\", va=\"center\", ha=\"right\", fontsize=8)\n",
        "\n",
        "fig.tight_layout()\n",
        "path_combined = output_sensitivity / \"sensitivity_metrics_combined.png\"\n",
        "fig.savefig(str(path_combined), dpi=200, bbox_inches=\"tight\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "254ea2da",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare input data and region mapping\n",
        "glacier_mass_file = input_rel / \"glacier_mass_2000.csv\"\n",
        "glacier_mass_df = pd.read_csv(str(glacier_mass_file), sep=\";\")\n",
        "glacier_mass_dict = dict(zip(glacier_mass_df[\"Region\"], glacier_mass_df[\"Mass\"]))\n",
        "\n",
        "# Region mappings\n",
        "regions_bar = {\n",
        "    \"1_alaska\": \"Alaska\",\n",
        "    \"2_western_canada_us\": \"W. Canada & US\",\n",
        "    \"3_arctic_canada_north\": \"Arctic Canada N.\",\n",
        "    \"4_arctic_canada_south\": \"Arctic Canada S.\",\n",
        "    \"5_greenland_periphery\": \"Greenland Per.\",\n",
        "    \"6_iceland\": \"Iceland\",\n",
        "    \"7_svalbard\": \"Svalbard\",\n",
        "    \"8_scandinavia\": \"Scandinavia\",\n",
        "    \"9_russian_arctic\": \"Russian Arctic\",\n",
        "    \"10_north_asia\": \"North Asia\",\n",
        "    \"11_central_europe\": \"Central Europe\",\n",
        "    \"12_caucasus_middle_east\": \"Caucasus & M.E.\",\n",
        "    \"13_central_asia\": \"Central Asia\",\n",
        "    \"14_south_asia_west\": \"South Asia W.\",\n",
        "    \"15_south_asia_east\": \"South Asia E.\",\n",
        "    \"16_low_latitudes\": \"Low Latitudes\",\n",
        "    \"17_southern_andes\": \"Southern Andes\",\n",
        "    \"18_new_zealand\": \"New Zealand\",\n",
        "    \"19_antarctic_and_subantarctic\": \"Antarctic & Sub.\",\n",
        "}\n",
        "\n",
        "mass_lookup = {\n",
        "    \"Alaska\": \"Alaska\",\n",
        "    \"W. Canada & US\": \"Western Canada and USA\",\n",
        "    \"Arctic Canada N.\": \"Arctic Canada north\",\n",
        "    \"Arctic Canada S.\": \"Arctic Canada south\",\n",
        "    \"Greenland Per.\": \"Greenland periphery\",\n",
        "    \"Iceland\": \"Iceland\",\n",
        "    \"Svalbard\": \"Svalbard and Jan Mayen\",\n",
        "    \"Scandinavia\": \"Scandinavia\",\n",
        "    \"Russian Arctic\": \"Russian Arctic\",\n",
        "    \"North Asia\": \"North Asia\",\n",
        "    \"Central Europe\": \"Central Europe\",\n",
        "    \"Caucasus & M.E.\": \"Caucasus and Middle East\",\n",
        "    \"Central Asia\": \"Central Asia\",\n",
        "    \"South Asia W.\": \"South Asia west\",\n",
        "    \"South Asia E.\": \"South Asia east\",\n",
        "    \"Low Latitudes\": \"Low latitudes\",\n",
        "    \"Southern Andes\": \"Southern Andes\",\n",
        "    \"New Zealand\": \"New Zealand\",\n",
        "    \"Antarctic & Sub.\": \"Antarctic and subantarctic islands\",\n",
        "    \"Global\": \"Global\",\n",
        "}\n",
        "\n",
        "def compute_all_metrics(df1, df2, glacier_mass, start_year=None, end_year=None):\n",
        "    merged = pd.merge(df1, df2, on=\"start_dates\", suffixes=(\"_run1\", \"_run2\"), how=\"outer\")\n",
        "    if start_year is not None:\n",
        "        merged = merged[merged[\"start_dates\"] >= start_year]\n",
        "    if end_year is not None:\n",
        "        merged = merged[merged[\"start_dates\"] <= end_year]\n",
        "    merged = merged.dropna(subset=[\"changes_run1\", \"changes_run2\"])\n",
        "    diff = merged[\"changes_run1\"] - merged[\"changes_run2\"]\n",
        "    cumul_run1 = merged[\"changes_run1\"].sum()\n",
        "    cumul_run2 = merged[\"changes_run2\"].sum()\n",
        "    if abs(cumul_run1) > 0.01:\n",
        "        rel_diff = (cumul_run2 - cumul_run1) / abs(cumul_run1) * 100.0\n",
        "    else:\n",
        "        rel_diff = 0.0\n",
        "    abs_diff = cumul_run2 - cumul_run1\n",
        "    corr, _ = spearmanr(merged[\"changes_run1\"], merged[\"changes_run2\"])\n",
        "    return rel_diff, abs_diff, corr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24936278",
      "metadata": {},
      "source": [
        "### Compare all runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "356d845c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Discover runs\n",
        "all_runs = sorted([\n",
        "    p for p in glambie_runs.iterdir()\n",
        "    if p.is_dir() and (p.name.startswith(\"datasets_\")  or p.name.startswith(\"datasets_default\"))\n",
        "])\n",
        "\n",
        "reference_run = next((r for r in all_runs if \"default\" in r.name), all_runs[0])\n",
        "print(f\"Reference run: {reference_run.name}\")\n",
        "\n",
        "summary_rows = []\n",
        "\n",
        "for run in all_runs:\n",
        "    if run == reference_run:\n",
        "        continue\n",
        "\n",
        "    start_year = None\n",
        "    end_year = None\n",
        "    # Year bounds: ETH from 2001, DUS-combined end at 2020, else end at 2019\n",
        "    # if \"ETH\" in run.name:\n",
        "    #     start_year, end_year = 2001, 2020\n",
        "    # elif \"DUS-combined\" in run.name:\n",
        "    #     start_year, end_year = None, 2020\n",
        "    # else:\n",
        "    #     start_year, end_year = None, 2019\n",
        "\n",
        "    region_names = []\n",
        "    rel_diff_values = []\n",
        "    abs_diff_values = []\n",
        "    corr_values = []\n",
        "\n",
        "    for region_dir, display_name in regions_bar.items():\n",
        "        region_key = \"_\".join(region_dir.split(\"_\")[1:])\n",
        "        csv1 = reference_run / region_dir / \"consensus\" / \"csvs\" / f\"consensus_calendar_year_gt_{region_key}.csv\"\n",
        "        csv2 = run / region_dir / \"consensus\" / \"csvs\" / f\"consensus_calendar_year_gt_{region_key}.csv\"\n",
        "\n",
        "        if not csv1.exists() or not csv2.exists():\n",
        "            continue\n",
        "\n",
        "        df1 = pd.read_csv(str(csv1))\n",
        "        df2 = pd.read_csv(str(csv2))\n",
        "        mass_key = mass_lookup.get(display_name, display_name)\n",
        "        glacier_mass = glacier_mass_dict.get(mass_key, None)\n",
        "        rel_diff, abs_diff, corr = compute_all_metrics(\n",
        "            df1, df2, glacier_mass, start_year=start_year, end_year=end_year\n",
        "        )\n",
        "\n",
        "        region_names.append(display_name)\n",
        "        rel_diff_values.append(rel_diff)\n",
        "        abs_diff_values.append(abs_diff)\n",
        "        corr_values.append(corr)\n",
        "\n",
        "    # Global\n",
        "    csv1_global = reference_run / \"0_global\" / \"consensus\" / \"csvs\" / \"global_gt.csv\"\n",
        "    csv2_global = run / \"0_global\" / \"consensus\" / \"csvs\" / \"global_gt.csv\"\n",
        "    if csv1_global.exists() and csv2_global.exists():\n",
        "        df1 = pd.read_csv(str(csv1_global))\n",
        "        df2 = pd.read_csv(str(csv2_global))\n",
        "        rel_diff, abs_diff, corr = compute_all_metrics(\n",
        "            df1, df2, glacier_mass_dict.get(\"Global\", None),\n",
        "            start_year=start_year, end_year=end_year\n",
        "        )\n",
        "        region_names.append(\"Global\")\n",
        "        rel_diff_values.append(rel_diff)\n",
        "        abs_diff_values.append(abs_diff)\n",
        "        corr_values.append(corr)\n",
        "\n",
        "    if not region_names:\n",
        "        continue\n",
        "\n",
        "    # Summary row (Global is last)\n",
        "    global_rel = rel_diff_values[-1]\n",
        "    global_abs = abs_diff_values[-1]\n",
        "    global_corr = corr_values[-1]\n",
        "    regional_rel = rel_diff_values[:-1]\n",
        "    regional_abs = abs_diff_values[:-1]\n",
        "\n",
        "    run_label = run.name.split(\"_\", 1)[1] if \"_\" in run.name else run.name\n",
        "\n",
        "    summary_rows.append({\n",
        "        \"Run\": run_label,\n",
        "        \"Global Rel Diff (%)\": global_rel,\n",
        "        \"Global Abs Diff (Gt)\": global_abs,\n",
        "        \"Global Correlation\": global_corr,\n",
        "        \"Mean |Regional Rel Diff| (%)\": np.mean(np.abs(regional_rel)) if regional_rel else np.nan,\n",
        "        \"Sum |Regional Abs Diff| (Gt)\": np.sum(np.abs(regional_abs)) if regional_abs else np.nan,\n",
        "    })\n",
        "\n",
        "    # Combined plot\n",
        "    fig, (ax3, ax4, ax5) = plt.subplots(1, 3, figsize=(18, 8), sharey=True)\n",
        "\n",
        "    # Panel 1: Relative difference\n",
        "    ax3.barh(range(len(region_names)), rel_diff_values)\n",
        "    ax3.set_yticks(range(len(region_names)))\n",
        "    ax3.set_yticklabels(region_names)\n",
        "    ax3.invert_yaxis()\n",
        "    ax3.set_xlabel(\"Relative Change (%)\")\n",
        "    # ax3.set_title(\"Relative Mass Difference (positive = more loss)\")\n",
        "    ax3.axvline(0, color=\"black\", linewidth=0.8)\n",
        "    max_abs_rel = max(abs(v) for v in rel_diff_values) or 1\n",
        "    for i, val in enumerate(rel_diff_values):\n",
        "        if val >= 0:\n",
        "            ax3.text(val + 0.02 * max_abs_rel, i, f\"+{val:.1f}%\", va=\"center\", fontsize=8)\n",
        "        else:\n",
        "            ax3.text(val - 0.02 * max_abs_rel, i, f\"{val:.1f}%\", va=\"center\", ha=\"right\", fontsize=8)\n",
        "    pad = max_abs_rel * 0.15\n",
        "    ax3.set_xlim(min(rel_diff_values) - pad, max(rel_diff_values) + pad)\n",
        "\n",
        "    # Panel 2: Absolute difference\n",
        "    ax4.barh(range(len(region_names)), abs_diff_values)\n",
        "    ax4.set_xlabel(\"Absolute Difference (Gt)\")\n",
        "    ax4.axvline(0, color=\"black\", linewidth=0.8)\n",
        "    max_abs_diff = max(abs(v) for v in abs_diff_values) or 1\n",
        "    for i, (val, rel) in enumerate(zip(abs_diff_values, rel_diff_values)):\n",
        "        if val >= 0:\n",
        "            ax4.text(val + 0.02 * max_abs_diff, i, f\"+{val:.2f}\", va=\"center\", fontsize=8)\n",
        "        else:\n",
        "            ax4.text(val - 0.02 * max_abs_diff, i, f\"{val:.2f}\", va=\"center\", ha=\"right\", fontsize=8)\n",
        "    pad = max_abs_diff * 0.30\n",
        "    ax4.set_xlim(min(abs_diff_values) - pad, max(abs_diff_values) + pad)\n",
        "\n",
        "    # Panel 3: Correlation\n",
        "    ax5.barh(range(len(region_names)), corr_values)\n",
        "    ax5.set_xlabel(\"Correlation\")\n",
        "    # ax5.set_title(\"Spearman Correlation\")\n",
        "    ax5.set_xlim(-0.1, 1.1)\n",
        "    for i, val in enumerate(corr_values):\n",
        "        if val >= 0:\n",
        "            ax5.text(val + 0.02, i, f\"{val:.2f}\", va=\"center\", fontsize=8)\n",
        "        else:\n",
        "            ax5.text(val + 0.08, i, f\"{val:.2f}\", va=\"center\", ha=\"right\", fontsize=8)\n",
        "\n",
        "    fig.suptitle(f\"{reference_run.name} vs {run_label}\", fontsize=12)\n",
        "    fig.tight_layout()\n",
        "    safe_name = run.name.replace(\" \", \"_\").replace(\"/\", \"-\")\n",
        "    path_combined = output_sensitivity / f\"sensitivity_{safe_name}.png\"\n",
        "    fig.savefig(str(path_combined), dpi=200, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "\n",
        "# Summary\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df = summary_df.reindex(\n",
        "    summary_df[\"Global Rel Diff (%)\"].abs().sort_values(ascending=False).index\n",
        ").reset_index(drop=True)\n",
        "\n",
        "summary_df.to_csv(output_sensitivity / \"run_influence_summary.csv\", index=False)\n",
        "summary_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c59da38",
      "metadata": {},
      "source": [
        "### Run metrics as barchart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a4cb0a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "region_rows = [] \n",
        "\n",
        "for run in [all_runs[i] for i in [0, 4, 5, 6, 7, 8, 9, 10, 11]]: # all_runs[0:4]:\n",
        "    if run == reference_run:\n",
        "        continue\n",
        "\n",
        "    run_label = run.name.split(\"_\", 1)[1] if \"_\" in run.name else run.name\n",
        "\n",
        "    for region_dir, display_name in regions_bar.items():\n",
        "        region_key = \"_\".join(region_dir.split(\"_\")[1:])\n",
        "        csv1 = reference_run / region_dir / \"consensus\" / \"csvs\" / f\"consensus_calendar_year_gt_{region_key}.csv\"\n",
        "        csv2 = run / region_dir / \"consensus\" / \"csvs\" / f\"consensus_calendar_year_gt_{region_key}.csv\"\n",
        "        if not csv1.exists() or not csv2.exists():\n",
        "            continue\n",
        "\n",
        "        df1 = pd.read_csv(csv1)\n",
        "        df2 = pd.read_csv(csv2)\n",
        "\n",
        "        rel_diff, abs_diff, corr = compute_all_metrics(df1, df2, glacier_mass=None)\n",
        "\n",
        "        region_rows.append({\n",
        "            \"Run\": run_label,\n",
        "            \"Region\": display_name,\n",
        "            \"RelDiffPct\": rel_diff,\n",
        "            \"AbsDiffGt\": abs_diff,\n",
        "            \"Corr\": corr\n",
        "        })\n",
        "\n",
        "    # Global\n",
        "    csv1_global = reference_run / \"0_global\" / \"consensus\" / \"csvs\" / \"global_gt.csv\"\n",
        "    csv2_global = run / \"0_global\" / \"consensus\" / \"csvs\" / \"global_gt.csv\"\n",
        "    if csv1_global.exists() and csv2_global.exists():\n",
        "        df1g = pd.read_csv(csv1_global)\n",
        "        df2g = pd.read_csv(csv2_global)\n",
        "        rel_diff, abs_diff, corr = compute_all_metrics(df1g, df2g, glacier_mass=None)\n",
        "\n",
        "        region_rows.append({\n",
        "            \"Run\": run_label,\n",
        "            \"Region\": \"Global\",\n",
        "            \"RelDiffPct\": rel_diff,\n",
        "            \"AbsDiffGt\": abs_diff,\n",
        "            \"Corr\": corr\n",
        "        })\n",
        "\n",
        "metrics_df = pd.DataFrame(region_rows)\n",
        "metrics_df[\"AbsRelDiffPct\"] = metrics_df[\"RelDiffPct\"].abs()\n",
        "metrics_df[\"AbsAbsDiffGt\"] = metrics_df[\"AbsDiffGt\"].abs()\n",
        "\n",
        "region_variability = (metrics_df.groupby(\"Region\")\n",
        "    .agg(\n",
        "        n_runs=(\"Run\", \"nunique\"),\n",
        "        mean_abs_rel=(\"AbsRelDiffPct\", \"mean\"),\n",
        "        std_abs_rel=(\"AbsRelDiffPct\", \"std\"),   \n",
        "        mean_rel = (\"RelDiffPct\", \"mean\"),\n",
        "        std_rel=(\"RelDiffPct\", \"std\"),\n",
        "        mean_abs_abs=(\"AbsAbsDiffGt\", \"mean\"),\n",
        "        std_abs_abs=(\"AbsAbsDiffGt\", \"std\"),   \n",
        "        mean_abs = (\"AbsDiffGt\", \"mean\"),\n",
        "        std_abs = (\"AbsDiffGt\", \"std\"),\n",
        "        mean_corr=(\"Corr\", \"mean\"),\n",
        "        min_corr=(\"Corr\", \"min\"),\n",
        "    )\n",
        "    .sort_values([\"Region\"], ascending=False)\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(14, 6), sharey=True)\n",
        "\n",
        "# color by direction\n",
        "sign_source = region_variability[\"mean_rel\"] \n",
        "\n",
        "bar_colors = [blue if v >= 0 else orange for v in sign_source]\n",
        "\n",
        "# relative difference\n",
        "ax1.barh(region_variability[\"Region\"], region_variability[\"mean_abs_rel\"],\n",
        "         xerr=region_variability[\"std_abs_rel\"],\n",
        "         color=bar_colors)\n",
        "ax1.set_xlabel(\"Mean |relative difference| (%)\") \n",
        "\n",
        "# absolute difference\n",
        "ax2.barh(region_variability[\"Region\"], region_variability[\"mean_abs_abs\"],\n",
        "         xerr=region_variability[\"std_abs_abs\"],\n",
        "         color=bar_colors)\n",
        "ax2.set_xlabel(\"Mean |absolute difference| (Gt)\")\n",
        "\n",
        "# Legend \n",
        "from matplotlib.patches import Patch\n",
        "handles = [Patch(facecolor=blue, label=\"Positive\"),  Patch(facecolor=orange, label=\"Negative\"),\n",
        "]\n",
        "\n",
        "fig.legend(handles=handles, loc=\"lower center\", ncol=2, frameon=False, title='Direction of change')\n",
        "plt.tight_layout(rect=[0, 0.07, 1, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab4540a0",
      "metadata": {},
      "source": [
        "**Notes, results and discussion**\n",
        "\n",
        "About those datasets\n",
        "- DUS-combined: combined at *annual* resolution available in 19 regions / never excluded\n",
        "- ETH: demdiff at *multi*-annual resolution available in 19 regions / never excluded\n",
        "- WGMS-beta: glaciological at *annual* resolution available in 19 regions / never exclued\n",
        "- Harig_Group: gravimetry at *sub*-annual resolution available in 10 regions / excluded in 4 regions\n",
        "- Jacob_2012_dmdt: gravimetry at *multi*-annual resolution in 17 regions / excluded in 17 regions\n",
        "- Sasgen_AWIarc_RL01: gravimetry at *sub*-annual available in 16 regions / excluded in 9 regions\n",
        "- Wouters: gravimetry at *sub*-annual resolution available in 17 regions / excluded in 10 regions\n",
        "- Treichler_ICESat: altimetry at *multi*-annual resolution available in 3 regions / excluded in 3 regions\n",
        "\n",
        "Results\n",
        "- DUS-combined causes relative difference of 11.6% or 756 GT and and the global change does not match regional ones\n",
        "    - This should not be the case: \"Global estimates were computed [...] by simple sums for global mass changes\" (Zemp et al., 2025)\n",
        "    - Seems to be because results for some regions seem to be missing for the final years \n",
        "- Other datasets such as Harig_Group cause almost no difference\n",
        "- Regions can shft a lot while global is not affected much\n",
        "    - Sasgen_AWIarc_RL01_2: 1.8% global change vs 57.6% mean regional relative difference\n",
        "    - Jacob_2012_dmdt: 7.1% global vs. 52.1% mean regional.\n",
        "\n",
        "Which datasets are still excluded from \"includin most\" datasets?\n",
        "- antarctic_and_subantarctic: Gardner2013_incesat\n",
        "- arctic_canada_north: Khan\n",
        "- arctic_canada_south: Khan\n",
        "- central_asia: Treichler_ICESat, Treichler_snowfall\n",
        "- greenland_periphery: Bolch_2013, Gardner2013_icesat\n",
        "- south_asia_east: Treichler_ICESat, Treichler_snowfall\n",
        "- south_asia_west: Treichler_ICESat, Treichler_snowfall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f718beb5",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import glob\n",
        "from scipy.stats import spearmanr\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Paths\n",
        "input_dir = Path(\"input\")\n",
        "output_dir = Path(\"output\")\n",
        "input_rel = input_dir / \"glambie_reference\"\n",
        "input_maps = input_dir / \"maps\"\n",
        "input_datasets = input_dir / \"input_datasets\"\n",
        "glambie_runs = input_dir / \"glambie_runs\"\n",
        "output_sensitivity = output_dir / \"sensitivity\"\n",
        "output_rel = output_dir / \"relative_change\"\n",
        "output_dir_datasets = output_dir / \"datasets\"\n",
        "\n",
        "# Initial glacier mass\n",
        "glacier_mass_file = input_rel / \"glacier_mass_2000.csv\"\n",
        "glacier_mass_df = pd.read_csv(str(glacier_mass_file), sep=\";\")\n",
        "glacier_mass_dict = dict(zip(glacier_mass_df[\"Region\"], glacier_mass_df[\"Mass\"]))\n",
        "\n",
        "\n",
        "def compute_all_metrics(df1, df2, glacier_mass):\n",
        "    merged = pd.merge(df1, df2, on=\"start_dates\", suffixes=(\"_run1\", \"_run2\"), how=\"outer\")\n",
        "    diff = merged[\"changes_run1\"] - merged[\"changes_run2\"]\n",
        "    cumul_run1 = merged[\"changes_run1\"].sum()\n",
        "    cumul_run2 = merged[\"changes_run2\"].sum()\n",
        "    if abs(cumul_run1) > 0.01:\n",
        "        rel_diff = (cumul_run2 - cumul_run1) / abs(cumul_run1) * 100.0\n",
        "    else:\n",
        "        rel_diff = 0.0\n",
        "    abs_diff = cumul_run2 - cumul_run1\n",
        "    corr, _ = spearmanr(merged[\"changes_run1\"], merged[\"changes_run2\"])\n",
        "    return rel_diff, abs_diff, corr\n",
        "\n",
        "\n",
        "# Global metrics only, for all runs starting with \"datasets_\"\n",
        "runs = sorted([\n",
        "    p for p in glambie_runs.iterdir()\n",
        "    if p.is_dir() and p.name.startswith(\"datasets_\")\n",
        "])\n",
        "reference_run = next((r for r in runs if \"default\" in r.name), runs[0])\n",
        "\n",
        "run_labels = []\n",
        "global_rel = []\n",
        "global_abs = []\n",
        "global_corr = []\n",
        "\n",
        "for run in runs:\n",
        "    if run == reference_run:\n",
        "        continue\n",
        "    csv_ref = reference_run / \"0_global\" / \"consensus\" / \"csvs\" / \"global_gt.csv\"\n",
        "    csv_run = run / \"0_global\" / \"consensus\" / \"csvs\" / \"global_gt.csv\"\n",
        "    if not csv_ref.exists() or not csv_run.exists():\n",
        "        continue\n",
        "    df1 = pd.read_csv(str(csv_ref))\n",
        "    df2 = pd.read_csv(str(csv_run))\n",
        "    rel_diff, abs_diff, corr = compute_all_metrics(\n",
        "        df1, df2, glacier_mass_dict.get(\"Global\", None))\n",
        "    label = run.name.split(\"_\", 1)[1] if \"_\" in run.name else run.name\n",
        "    run_labels.append(label)\n",
        "    global_rel.append(rel_diff)\n",
        "    global_abs.append(abs_diff)\n",
        "    global_corr.append(corr)\n",
        "\n",
        "if not run_labels:\n",
        "    print(\"No runs to plot (or only reference run found).\")\n",
        "else:\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(16, max(6, len(run_labels) * 0.6)), sharey=True)\n",
        "\n",
        "    n = len(run_labels)\n",
        "    y_pos = np.arange(n)\n",
        "\n",
        "    # Panel 1: Global relative difference (%)\n",
        "    ax1.barh(y_pos, global_rel)\n",
        "    ax1.set_yticks(y_pos)\n",
        "    ax1.set_yticklabels(run_labels, fontsize=9)\n",
        "    ax1.invert_yaxis()\n",
        "    ax1.set_xlabel(\"Relative Change (%)\")\n",
        "    ax1.axvline(0, color=\"black\", linewidth=0.8)\n",
        "    max_abs_rel = max(abs(v) for v in global_rel) or 1\n",
        "    for i, val in enumerate(global_rel):\n",
        "        if val >= 0:\n",
        "            ax1.text(val + 0.02 * max_abs_rel, i, f\"+{val:.1f}%\", va=\"center\", fontsize=8)\n",
        "        else:\n",
        "            ax1.text(val - 0.02 * max_abs_rel, i, f\"{val:.1f}%\", va=\"center\", ha=\"right\", fontsize=8)\n",
        "    pad = max_abs_rel * 0.20\n",
        "    ax1.set_xlim(min(global_rel) - pad, max(global_rel) + pad)\n",
        "\n",
        "    # Panel 2: Global absolute difference (Gt)\n",
        "    ax2.barh(y_pos, global_abs)\n",
        "    ax2.set_xlabel(\"Absolute Difference (Gt)\")\n",
        "    ax2.axvline(0, color=\"black\", linewidth=0.8)\n",
        "    max_abs_diff = max(abs(v) for v in global_abs) or 1\n",
        "    for i, val in enumerate(global_abs):\n",
        "        if val >= 0:\n",
        "            ax2.text(val + 0.02 * max_abs_diff, i, f\"+{val:.2f}\", va=\"center\", fontsize=8)\n",
        "        else:\n",
        "            ax2.text(val - 0.02 * max_abs_diff, i, f\"{val:.2f}\", va=\"center\", ha=\"right\", fontsize=8)\n",
        "    pad = max_abs_diff * 0.30\n",
        "    ax2.set_xlim(min(global_abs) - pad, max(global_abs) + pad)\n",
        "\n",
        "    # Panel 3: Global correlation\n",
        "    ax3.barh(y_pos, global_corr)\n",
        "    ax3.set_xlabel(\"Correlation\")\n",
        "    ax3.set_xlim(-0.1, 1.2)\n",
        "    for i, val in enumerate(global_corr):\n",
        "        if val >= 0:\n",
        "            ax3.text(val + 0.02, i, f\"{val:.2f}\", va=\"center\", fontsize=8)\n",
        "        else:\n",
        "            ax3.text(val + 0.08, i, f\"{val:.2f}\", va=\"center\", ha=\"right\", fontsize=8)\n",
        "\n",
        "    fig.suptitle(f\"Global metrics vs {reference_run.name}\", fontsize=12)\n",
        "    fig.tight_layout()\n",
        "    fig.set_dpi(300)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e037dcff",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combined: global relative difference + mean regional variation per run\n",
        "runs = sorted([\n",
        "    p for p in glambie_runs.iterdir()\n",
        "    if p.is_dir() and p.name.startswith(\"datasets_\")\n",
        "])\n",
        "reference_run = next((r for r in runs if \"default\" in r.name), runs[0])\n",
        "\n",
        "run_labels = []\n",
        "global_rel = []\n",
        "mean_regional_rel = []\n",
        "\n",
        "start_year = None\n",
        "end_year = None\n",
        "\n",
        "for run in runs:\n",
        "    if run == reference_run:\n",
        "        continue\n",
        "    if \"ETH\" in run.name:\n",
        "        start_year, end_year = 2001, 2020\n",
        "    elif \"DUS-combined\" in run.name:\n",
        "        start_year, end_year = None, 2020\n",
        "    else:\n",
        "        start_year, end_year = None, 2019\n",
        "\n",
        "    # Global metric\n",
        "    csv_ref_global = reference_run / \"0_global\" / \"consensus\" / \"csvs\" / \"global_gt.csv\"\n",
        "    csv_run_global = run / \"0_global\" / \"consensus\" / \"csvs\" / \"global_gt.csv\"\n",
        "    if not csv_ref_global.exists() or not csv_run_global.exists():\n",
        "        continue\n",
        "    df1_g = pd.read_csv(str(csv_ref_global))\n",
        "    df2_g = pd.read_csv(str(csv_run_global))\n",
        "    rel_global, _, _ = compute_all_metrics(\n",
        "        df1_g, df2_g, glacier_mass_dict.get(\"Global\", None),\n",
        "        start_year=start_year, end_year=end_year\n",
        "    )\n",
        "\n",
        "    # Regional metrics (mean |rel diff|)\n",
        "    rel_diffs = []\n",
        "    for region_dir, display_name in regions_bar.items():\n",
        "        region_key = \"_\".join(region_dir.split(\"_\")[1:])\n",
        "        csv1 = reference_run / region_dir / \"consensus\" / \"csvs\" / f\"consensus_calendar_year_gt_{region_key}.csv\"\n",
        "        csv2 = run / region_dir / \"consensus\" / \"csvs\" / f\"consensus_calendar_year_gt_{region_key}.csv\"\n",
        "        if not csv1.exists() or not csv2.exists():\n",
        "            continue\n",
        "        df1 = pd.read_csv(str(csv1))\n",
        "        df2 = pd.read_csv(str(csv2))\n",
        "        mass_key = mass_lookup.get(display_name, display_name)\n",
        "        glacier_mass = glacier_mass_dict.get(mass_key, None)\n",
        "        rel_diff, _, _ = compute_all_metrics(\n",
        "            df1, df2, glacier_mass, start_year=start_year, end_year=end_year\n",
        "        )\n",
        "        rel_diffs.append(rel_diff)\n",
        "\n",
        "    if not rel_diffs:\n",
        "        continue\n",
        "    label = run.name.split(\"_\", 1)[1] if \"_\" in run.name else run.name\n",
        "    run_labels.append(label)\n",
        "    global_rel.append(rel_global)\n",
        "    mean_regional_rel.append(np.mean(np.abs(rel_diffs)))\n",
        "\n",
        "if not run_labels:\n",
        "    print(\"No runs to plot.\")\n",
        "else:\n",
        "    n = len(run_labels)\n",
        "    y_pos = np.arange(n)\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, max(5, n * 0.6)), sharey=True)\n",
        "\n",
        "    # Panel 1: Global relative difference (%)\n",
        "    ax1.barh(y_pos, global_rel)\n",
        "    ax1.set_yticks(y_pos)\n",
        "    ax1.set_yticklabels(run_labels, fontsize=9)\n",
        "    ax1.invert_yaxis()\n",
        "    ax1.set_xlabel(\"Global relative difference (%)\")\n",
        "    ax1.axvline(0, color=\"black\", linewidth=0.8)\n",
        "    for i, val in enumerate(global_rel):\n",
        "        x = val + (0.02 * (max(global_rel) - min(global_rel)) or 1) if val >= 0 else val - (0.02 * (max(global_rel) - min(global_rel)) or 1)\n",
        "        ax1.text(val + 0.5 if val >= 0 else val - 0.5, i, f\"{val:+.1f}%\", va=\"center\", ha=\"left\" if val >= 0 else \"right\", fontsize=8)\n",
        "    pad = (max(global_rel) - min(global_rel)) * 0.2 or 1\n",
        "    ax1.set_xlim(min(global_rel) - pad, max(global_rel) + pad)\n",
        "\n",
        "    # Panel 2: Mean |regional relative difference| (%)\n",
        "    ax2.barh(y_pos, mean_regional_rel)\n",
        "    ax2.set_xlabel(\"Mean |Regional relative difference| (%)\")\n",
        "    ax2.axvline(0, color=\"black\", linewidth=0.8)\n",
        "    for i, val in enumerate(mean_regional_rel):\n",
        "        ax2.text(val + 0.1, i, f\"{val:.1f}%\", va=\"center\", fontsize=8)\n",
        "    pad = max(mean_regional_rel) * 0.15 or 0.5\n",
        "    ax2.set_xlim(0, max(mean_regional_rel) + pad)\n",
        "\n",
        "    fig.suptitle(f\"Adjusted datasets vs reference run\", fontsize=12)\n",
        "    fig.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c2467be",
      "metadata": {},
      "source": [
        "## Map visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "947e0157",
      "metadata": {},
      "source": [
        "Create maps which show differences between dataset inclusions per region. \n",
        "- Root mean squared difference\n",
        "- Mean absolute difference\n",
        "- Relative difference in overall mass change\n",
        "- Absolute difference in overall mass change"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffc7af01",
      "metadata": {},
      "source": [
        "### Default vs all datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15310cb7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Map plots\n",
        "glacreg_path = input_maps / \"GlacReg_2023\" / \"GTN-G_202307_o1regions.shp\"\n",
        "glacier_regions = gpd.read_file(str(glacreg_path))\n",
        "\n",
        "# Positioning\n",
        "regions_map = {\n",
        "    \"1_alaska\":                      (\"Alaska\",            63.0, -150.0, 1),\n",
        "    \"2_western_canada_us\":           (\"W. Canada & US\",    50.0, -122.0, 2),\n",
        "    \"3_arctic_canada_north\":         (\"Arctic Canada N.\",  77.0,  -82.0, 3),\n",
        "    \"4_arctic_canada_south\":         (\"Arctic Canada S.\",  66.0,  -70.0, 4),\n",
        "    \"5_greenland_periphery\":         (\"Greenland Per.\",    72.0,  -42.0, 5),\n",
        "    \"6_iceland\":                     (\"Iceland\",           65.0,  -19.0, 6),\n",
        "    \"7_svalbard\":                    (\"Svalbard\",          78.0,   17.0, 7),\n",
        "    \"8_scandinavia\":                 (\"Scandinavia\",       67.0,   15.0, 8),\n",
        "    \"9_russian_arctic\":              (\"Russian Arctic\",    77.0,   60.0, 9),\n",
        "    \"10_north_asia\":                 (\"North Asia\",        50.0,   90.0, 10),\n",
        "    \"11_central_europe\":             (\"Central Europe\",    47.0,   11.0, 11),\n",
        "    \"12_caucasus_middle_east\":       (\"Caucasus & M.E.\",   42.0,   44.0, 12),\n",
        "    \"13_central_asia\":               (\"Central Asia\",      40.0,   75.0, 13),\n",
        "    \"14_south_asia_west\":            (\"South Asia W.\",     35.0,   74.0, 14),\n",
        "    \"15_south_asia_east\":            (\"South Asia E.\",     30.0,   90.0, 15),\n",
        "    \"16_low_latitudes\":              (\"Low Latitudes\",     -1.0,  -78.0, 16),\n",
        "    \"17_southern_andes\":             (\"Southern Andes\",   -47.0,  -73.0, 17),\n",
        "    \"18_new_zealand\":                (\"New Zealand\",      -44.0,  170.0, 18),\n",
        "    \"19_antarctic_and_subantarctic\": (\"Antarctic & Sub.\", -70.0,    0.0, 19),\n",
        "}\n",
        "\n",
        "label_positions = {\n",
        "    \"Alaska\":            (-170.0, 55.0),\n",
        "    \"W. Canada & US\":    (-140.0, 42.0),\n",
        "    \"Arctic Canada N.\":  (-100.0, 82.0),\n",
        "    \"Arctic Canada S.\":  (-85.0, 72.0),\n",
        "    \"Greenland Per.\":    (-50.0, 78.0),\n",
        "    \"Iceland\":           (-30.0, 68.0),\n",
        "    \"Svalbard\":          (10.0, 82.0),\n",
        "    \"Scandinavia\":       (5.0, 72.0),\n",
        "    \"Russian Arctic\":    (70.0, 82.0),\n",
        "    \"North Asia\":        (110.0, 55.0),\n",
        "    \"Central Europe\":    (0.0, 50.0),\n",
        "    \"Caucasus & M.E.\":   (55.0, 48.0),\n",
        "    \"Central Asia\":      (85.0, 45.0),\n",
        "    \"South Asia W.\":     (65.0, 30.0),\n",
        "    \"South Asia E.\":     (100.0, 25.0),\n",
        "    \"Low Latitudes\":     (-90.0, -8.0),\n",
        "    \"Southern Andes\":    (-80.0, -52.0),\n",
        "    \"New Zealand\":       (175.0, -50.0),\n",
        "    \"Antarctic & Sub.\":  (-10.0, -75.0),\n",
        "}\n",
        "\n",
        "data = []\n",
        "for i, (region_dir, (display_name, lat, lon, region_num)) in enumerate(regions_map.items()):\n",
        "    data.append({\n",
        "        \"name\": display_name,\n",
        "        \"lat\": lat,\n",
        "        \"lon\": lon,\n",
        "        \"region_num\": region_num,\n",
        "        \"rel_diff\": rel_diff_values[i],\n",
        "        \"abs_diff\": abs_diff_values[i],\n",
        "        \"corr\": corr_values[i],\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Global is the last element in the barchart lists\n",
        "global_metrics = {\n",
        "    \"rel_diff\": rel_diff_values[-1],\n",
        "    \"abs_diff\": abs_diff_values[-1],\n",
        "    \"corr\": corr_values[-1],\n",
        "}\n",
        "\n",
        "map_configs = [\n",
        "    {\n",
        "        \"metric\": \"rel_diff\",\n",
        "        \"title\": \"Relative Difference in Total Mass Change\\n(default vs. all datasets)\",\n",
        "        \"cmap\": \"RdBu_r\",\n",
        "        \"label\": \"Relative Difference (%)\",\n",
        "        \"diverging\": True,\n",
        "        \"output\": \"map_relative_difference.png\",\n",
        "        \"fmt\": \"+.1f\",\n",
        "        \"unit\": \"%\",\n",
        "    },\n",
        "    {\n",
        "        \"metric\": \"abs_diff\",\n",
        "        \"title\": \"Absolute Mass Change Difference Between Glambie Runs\\n(default vs. all datasets)\",\n",
        "        \"cmap\": \"RdBu_r\",\n",
        "        \"label\": \"Absolute Difference (Gt)\",\n",
        "        \"diverging\": True,\n",
        "        \"output\": \"map_absolute_difference.png\",\n",
        "        \"fmt\": \"+.2f\",\n",
        "        \"unit\": \" Gt\",\n",
        "    },\n",
        "    {\n",
        "        \"metric\": \"corr\",\n",
        "        \"title\": \"Correlation Between Glambie Runs\\n(default vs. all datasets)\",\n",
        "        \"cmap\": \"RdYlGn\",\n",
        "        \"label\": \"Correlation\",\n",
        "        \"diverging\": False,\n",
        "        \"output\": \"map_correlation.png\",\n",
        "        \"fmt\": \".2f\",\n",
        "        \"unit\": \"\",\n",
        "    },\n",
        "]\n",
        "\n",
        "for cfg in map_configs:\n",
        "    metric = cfg[\"metric\"]\n",
        "    title = cfg[\"title\"]\n",
        "    cmap = cfg[\"cmap\"]\n",
        "    label = cfg[\"label\"]\n",
        "    diverging = cfg[\"diverging\"]\n",
        "    output_path = output_sensitivity / cfg[\"output\"]\n",
        "    fmt = cfg[\"fmt\"]\n",
        "    unit = cfg[\"unit\"]\n",
        "\n",
        "    values = df[metric].values\n",
        "    global_val = global_metrics.get(metric, None)\n",
        "\n",
        "    fig = plt.figure(figsize=(20, 11))\n",
        "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.Robinson())\n",
        "\n",
        "    ax.add_feature(cfeature.OCEAN, facecolor='white', zorder=0)\n",
        "    ax.add_feature(cfeature.LAND, facecolor='#e0e0e0', edgecolor='#aaaaaa', linewidth=0.3, zorder=1)\n",
        "    ax.add_feature(cfeature.COASTLINE, linewidth=0.4, edgecolor='#666666', zorder=2)\n",
        "\n",
        "    glaciers = cfeature.NaturalEarthFeature(\n",
        "        'physical', 'glaciated_areas', '50m',\n",
        "        edgecolor='#2e5f7f', facecolor='#4a8fc4', linewidth=0.2\n",
        "    )\n",
        "    ax.add_feature(glaciers, zorder=3, alpha=0.7)\n",
        "\n",
        "    if glacier_regions is not None:\n",
        "        ax.add_geometries(\n",
        "            glacier_regions.geometry,\n",
        "            crs=ccrs.PlateCarree(),\n",
        "            facecolor='none',\n",
        "            edgecolor='#5a5a5a',\n",
        "            linewidth=1.0,\n",
        "            linestyle='--',\n",
        "            zorder=4,\n",
        "            alpha=0.6\n",
        "        )\n",
        "    ax.set_global()\n",
        "\n",
        "    vals = np.array(values)\n",
        "    abs_vals = np.abs(vals)\n",
        "\n",
        "    if global_val is not None:\n",
        "        size_scale = max(abs_vals.max(), abs(global_val))\n",
        "    else:\n",
        "        size_scale = abs_vals.max()\n",
        "\n",
        "    sizes = (abs_vals / size_scale) * 5000\n",
        "\n",
        "    if diverging:\n",
        "        all_vals = list(vals) + ([global_val] if global_val is not None else [])\n",
        "        vmax_abs = max(abs(min(all_vals)), abs(max(all_vals)))\n",
        "        vmin, vmax = -vmax_abs, vmax_abs\n",
        "        norm = mcolors.TwoSlopeNorm(vmin=vmin, vcenter=0, vmax=vmax)\n",
        "    else:\n",
        "        vmin = 0\n",
        "        all_vals = list(vals) + ([global_val] if global_val is not None else [])\n",
        "        vmax = max(all_vals)\n",
        "        norm = mcolors.Normalize(vmin=vmin, vmax=vmax)\n",
        "\n",
        "    sc = ax.scatter(\n",
        "        df[\"lon\"], df[\"lat\"],\n",
        "        c=vals, s=sizes,\n",
        "        cmap=cmap, norm=norm,\n",
        "        edgecolors=\"0.2\", linewidths=1.0,\n",
        "        zorder=8, alpha=0.75,\n",
        "        transform=ccrs.PlateCarree()\n",
        "    )\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        region_name = row[\"name\"]\n",
        "        val = row[metric]\n",
        "        val_str = f\"{val:{fmt}}{unit}\"\n",
        "\n",
        "        if region_name in label_positions:\n",
        "            label_lon, label_lat = label_positions[region_name]\n",
        "\n",
        "            ax.text(\n",
        "                label_lon, label_lat,\n",
        "                f\"{region_name}\\n{val_str}\",\n",
        "                fontsize=7, ha=\"center\", va='center',\n",
        "                color=\"0.1\",\n",
        "                bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"0.4\", alpha=0.85, linewidth=0.5),\n",
        "                transform=ccrs.PlateCarree(),\n",
        "                zorder=12\n",
        "            )\n",
        "\n",
        "            ax.plot(\n",
        "                [label_lon, row[\"lon\"]], [label_lat, row[\"lat\"]],\n",
        "                color='0.5', linewidth=0.4, linestyle='-', alpha=0.5,\n",
        "                transform=ccrs.PlateCarree(),\n",
        "                zorder=7\n",
        "            )\n",
        "\n",
        "    if global_val is not None:\n",
        "        global_lon, global_lat = 0.0, -20.0\n",
        "        global_size = (abs(global_val) / size_scale) * 5000\n",
        "\n",
        "        ax.scatter(\n",
        "            [global_lon], [global_lat],\n",
        "            c=[global_val], s=[global_size * 1.5],\n",
        "            cmap=cmap, norm=norm,\n",
        "            edgecolors=\"0.1\", linewidths=1.0,\n",
        "            zorder=11, alpha=0.9,\n",
        "            marker=\"o\",\n",
        "            transform=ccrs.PlateCarree()\n",
        "        )\n",
        "\n",
        "        val_str = f\"{global_val:{fmt}}{unit}\"\n",
        "        ax.text(\n",
        "            global_lon, global_lat - 8,\n",
        "            f\"Global\\n{val_str}\",\n",
        "            fontsize=9, fontweight=\"bold\", ha=\"center\", va='top',\n",
        "            color=\"0.05\",\n",
        "            bbox=dict(boxstyle=\"round,pad=0.35\", fc=\"white\", ec=\"0.3\", alpha=0.95, linewidth=1),\n",
        "            transform=ccrs.PlateCarree(),\n",
        "            zorder=12\n",
        "        )\n",
        "\n",
        "    cb = plt.colorbar(sc, ax=ax, shrink=0.5, pad=0.03, aspect=20, orientation='vertical')\n",
        "    cb.set_label(label, fontsize=11)\n",
        "    cb.ax.tick_params(labelsize=9)\n",
        "\n",
        "    ax.set_title(title, fontsize=13, pad=15)\n",
        "\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(str(output_path), dpi=200)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1807881d",
      "metadata": {},
      "source": [
        "### Aggregate dataset differences between regions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "064c8412",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build\n",
        "name_to_lonlat = {}\n",
        "for region_dir, (display_name, lat, lon, region_num) in regions_map.items():\n",
        "    name_to_lonlat[display_name] = (lon, lat)\n",
        "name_to_lonlat[\"Global\"] = (0.0, -20.0)\n",
        "\n",
        "# DataFrame from region_variability\n",
        "rows = []\n",
        "for _, row in region_variability.iterrows():\n",
        "    name = row[\"Region\"]\n",
        "    if name not in name_to_lonlat:\n",
        "        continue\n",
        "    lon, lat = name_to_lonlat[name]\n",
        "    rows.append({\n",
        "        \"name\": name,\n",
        "        \"lat\": lat,\n",
        "        \"lon\": lon,\n",
        "        \"mean_abs_rel\": row[\"mean_abs_rel\"],\n",
        "        \"mean_abs_abs\": row[\"mean_abs_abs\"],\n",
        "    })\n",
        "df = pd.DataFrame(rows)\n",
        "\n",
        "# Separate Global for plotting (optional, same as your current style)\n",
        "df_regions = df[df[\"name\"] != \"Global\"]\n",
        "global_row = df[df[\"name\"] == \"Global\"]\n",
        "global_metrics = global_row.iloc[0].to_dict() if len(global_row) else {}\n",
        "\n",
        "# Single map: mean_abs_rel = color, mean_abs_abs = size\n",
        "metric_color = \"mean_abs_rel\"\n",
        "metric_size = \"mean_abs_abs\"\n",
        "cmap = \"RdBu_r\"\n",
        "label_color = \"Mean relative change (%)\"\n",
        "output_path = output_sensitivity / \"map_region_variability.png\"  # or your preferred path\n",
        "\n",
        "fig = plt.figure(figsize=(20, 11))\n",
        "ax = fig.add_subplot(1, 1, 1, projection=ccrs.Robinson())\n",
        "\n",
        "ax.add_feature(cfeature.OCEAN, facecolor='white', zorder=0)\n",
        "ax.add_feature(cfeature.LAND, facecolor='#e0e0e0', edgecolor='#aaaaaa', linewidth=0.3, zorder=1)\n",
        "ax.add_feature(cfeature.COASTLINE, linewidth=0.4, edgecolor='#666666', zorder=2)\n",
        "glaciers = cfeature.NaturalEarthFeature(\n",
        "    'physical', 'glaciated_areas', '50m',\n",
        "    edgecolor='#2e5f7f', facecolor='#4a8fc4', linewidth=0.2\n",
        ")\n",
        "ax.add_feature(glaciers, zorder=3, alpha=0.7)\n",
        "if glacier_regions is not None:\n",
        "    ax.add_geometries(\n",
        "        glacier_regions.geometry,\n",
        "        crs=ccrs.PlateCarree(),\n",
        "        facecolor='none',\n",
        "        edgecolor='#5a5a5a',\n",
        "        linewidth=1.0,\n",
        "        linestyle='--',\n",
        "        zorder=4,\n",
        "        alpha=0.6\n",
        "    )\n",
        "ax.set_global()\n",
        "\n",
        "# Size from mean_abs (same scaling idea as your original)\n",
        "vals_size = df_regions[metric_size].values\n",
        "size_scale = vals_size.max()\n",
        "if global_metrics and metric_size in global_metrics:\n",
        "    size_scale = max(size_scale, global_metrics[metric_size])\n",
        "sizes = (df_regions[metric_size].values / size_scale) * 5000\n",
        "\n",
        "# Color from mean_rel (diverging)\n",
        "vals_color = df_regions[metric_color].values\n",
        "all_color = list(vals_color)\n",
        "vmin, vmax = min(all_color), max(all_color)\n",
        "norm = mcolors.TwoSlopeNorm(vmin=vmin, vcenter=50, vmax=vmax)\n",
        "\n",
        "sc = ax.scatter(\n",
        "    df_regions[\"lon\"], df_regions[\"lat\"],\n",
        "    c=vals_color, s=sizes,\n",
        "    cmap=cmap, norm=norm,\n",
        "    edgecolors=\"0.2\", linewidths=1.0,\n",
        "    zorder=8, alpha=0.75,\n",
        "    transform=ccrs.PlateCarree()\n",
        ")\n",
        "\n",
        "# Labels and leader lines (same as your plots)\n",
        "for _, row in df_regions.iterrows():\n",
        "    region_name = row[\"name\"]\n",
        "    val = row[metric_color]\n",
        "    val_str = f\" {val:+.2f}%\\n({row[metric_size]:.1f} Gt)\"  # mean_rel and mean_abs\n",
        "\n",
        "    if region_name in label_positions:\n",
        "        label_lon, label_lat = label_positions[region_name]\n",
        "        ax.text(\n",
        "            label_lon, label_lat,\n",
        "            f\"{region_name}\\n{val_str}\",\n",
        "            fontsize=7, ha=\"center\", va='center',\n",
        "            color=\"0.1\",\n",
        "            bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"0.4\", alpha=0.85, linewidth=0.5),\n",
        "            transform=ccrs.PlateCarree(),\n",
        "            zorder=12\n",
        "        )\n",
        "        ax.plot(\n",
        "            [label_lon, row[\"lon\"]], [label_lat, row[\"lat\"]],\n",
        "            color='0.5', linewidth=0.4, linestyle='-', alpha=0.5,\n",
        "            transform=ccrs.PlateCarree(),\n",
        "            zorder=7\n",
        "        )\n",
        "\n",
        "# Global point\n",
        "g = global_row.iloc[0]\n",
        "global_lon, global_lat = 0.0, -20.0\n",
        "global_size = (g[metric_size] / size_scale) * 5000 * 1.5\n",
        "ax.scatter(\n",
        "    [global_lon], [global_lat],\n",
        "    c=[g[metric_color]], s=[global_size],\n",
        "    cmap=cmap, norm=norm,\n",
        "    edgecolors=\"0.1\", linewidths=1.0,\n",
        "    zorder=11, alpha=0.9,\n",
        "    marker=\"o\",\n",
        "    transform=ccrs.PlateCarree()\n",
        ")\n",
        "ax.text(\n",
        "    global_lon, global_lat - 8,\n",
        "    f\"Global\\n {g[metric_color]:+.2f}%\\n({g[metric_size]:.1f} Gt)\",\n",
        "    fontsize=9, fontweight=\"bold\", ha=\"center\", va='top',\n",
        "    color=\"0.05\",\n",
        "    bbox=dict(boxstyle=\"round,pad=0.35\", fc=\"white\", ec=\"0.3\", alpha=0.95, linewidth=1),\n",
        "    transform=ccrs.PlateCarree(),\n",
        "    zorder=12\n",
        ")\n",
        "\n",
        "# Size legend: circles + labels for mean_abs\n",
        "size_legend_vals = [10, 40, 70, 100]   # 4 circles\n",
        "size_scale_leg = max(np.abs(df_regions[metric_size]).max(), 1.0)\n",
        "legend_ax = fig.add_axes([0.02, 0.36, 0.18, 0.25])\n",
        "legend_ax.set_facecolor(\"white\")\n",
        "legend_ax.axis(\"off\")\n",
        "legend_ax.set_xlim(-2, 4)\n",
        "legend_ax.set_ylim(-2, 4)\n",
        "legend_ax.set_aspect(\"equal\")\n",
        "for i, v in enumerate(size_legend_vals):\n",
        "    s = (v / size_scale_leg) * 5000\n",
        "    s = max(s, 5)\n",
        "    legend_ax.scatter(0, 2.5 - i * 1, s=s, c=\"grey\", alpha=0.8, edgecolors=\"0.5\")\n",
        "    legend_ax.text(1.5, 2.5 - i * 1, f\"{v:.0f}\", fontsize=10, va=\"center\")\n",
        "legend_ax.text(1.4, -1.8, \"Mean absolute\\nchange (Gt)\", fontsize=10, style=\"italic\")\n",
        "\n",
        "cb = plt.colorbar(sc, ax=ax, shrink=0.5, pad=0.03, aspect=20, orientation='vertical')\n",
        "cb.set_label(label_color, fontsize=11)\n",
        "cb.ax.tick_params(labelsize=9)\n",
        "fig.tight_layout()\n",
        "fig.savefig(str(output_path), dpi=200)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "glambie",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
