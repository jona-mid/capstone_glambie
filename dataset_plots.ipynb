{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "497cd08f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Plotting input datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7a5ec2",
   "metadata": {},
   "source": [
    "Plot input data, colored by inclusion (green shades) and exclusion (red shades) of datasets used to produce the results of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e789fded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import pymannkendall as mk\n",
    "import warnings\n",
    "import geopandas as gpd\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Paths\n",
    "input_dir = Path(\"input\")\n",
    "output_dir = Path(\"output\")\n",
    "input_rel = input_dir / \"glambie_reference\"\n",
    "input_maps = input_dir / \"maps\"\n",
    "input_datasets = input_dir / \"input_datasets\"\n",
    "glambie_runs = input_dir / \"glambie_runs\"\n",
    "output_sensitivity = output_dir / \"sensitivity\"\n",
    "output_rel = output_dir / \"relative_change\"\n",
    "output_dir_datasets = output_dir / \"datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4c0398",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {'start_dates', 'end_dates', 'changes', 'errors'}\n",
    "included_colors = ['#2ecc71', '#27ae60', '#229954', '#1e8449', '#196f3d']\n",
    "excluded_colors = ['#e74c3c', '#c0392b', '#a93226', '#922b21', '#7b241c']\n",
    "\n",
    "# included_colors = ['#2ecc71', '#00acc1', '#558b2f', '#26a69a', '#0277bd', '#7cb342', '#00695c', '#43a047', '#00838f', '#1b5e20']\n",
    "# excluded_colors = ['#e53935', '#fb8c00', '#d81b60', '#8d6e63', '#f4511e', '#ad1457', '#c62828', '#ef6c00', '#e91e63', '#6d4c41']\n",
    "\n",
    "# Load excluded list\n",
    "excluded_df = pd.read_csv(str(input_datasets / 'excluded_datasets_list.csv'))\n",
    "# excluded_df = excluded_df[excluded_df['inclusion_possible'].str.strip().str.lower() == 'no'] # plot only problematic datasets as \"excluded\"\n",
    "\n",
    "excluded_set = set()\n",
    "for _, row in excluded_df.iterrows():\n",
    "    region = row['region']\n",
    "    data_group = row['data_group']\n",
    "    dataset = str(row['dataset']).lower()\n",
    "\n",
    "    if data_group == 'demdiff_and_glaciological':\n",
    "        excluded_set.add((region, 'demdiff', dataset))\n",
    "        excluded_set.add((region, 'glaciological', dataset))\n",
    "    else:\n",
    "        excluded_set.add((region, data_group, dataset))\n",
    "\n",
    "# Datasets to completely remove from plots\n",
    "skip_datasets = set()\n",
    "\n",
    "# Load all datasets\n",
    "datasets = []\n",
    "base_dir = input_datasets\n",
    "skip_files = {'excluded_datasets_list.csv'}\n",
    "all_csv_files = [f for f in base_dir.rglob('*.csv') if f.name not in skip_files]\n",
    "\n",
    "for csv_file in all_csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        if not columns.issubset(df.columns):\n",
    "            continue\n",
    "\n",
    "        parts = csv_file.parts\n",
    "        if len(parts) < 3:\n",
    "            continue\n",
    "\n",
    "        region = parts[-3]\n",
    "        data_group = parts[-2]\n",
    "        dataset_name = csv_file.stem\n",
    "\n",
    "        if dataset_name in skip_datasets:\n",
    "            continue\n",
    "\n",
    "        unit = 'Gt' if data_group == 'gravimetry' else 'm'\n",
    "        is_excluded = (region, data_group, dataset_name.lower()) in excluded_set\n",
    "\n",
    "        datasets.append({\n",
    "            'region': region,\n",
    "            'data_group': data_group,\n",
    "            'dataset': dataset_name,\n",
    "            'unit': unit,\n",
    "            'is_excluded': is_excluded,\n",
    "            'data': df,\n",
    "            'filepath': csv_file\n",
    "        })\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "# Group by (region, unit)\n",
    "grouped = defaultdict(list)\n",
    "for ds in datasets:\n",
    "    grouped[(ds['region'], ds['unit'])].append(ds)\n",
    "\n",
    "# Plot per group\n",
    "for (region, unit), group_datasets in sorted(grouped.items()):\n",
    "    print(f\"Plotting {region, unit}\")\n",
    "    if not group_datasets:\n",
    "        continue\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "    included = [ds for ds in group_datasets if not ds['is_excluded']]\n",
    "    excluded = [ds for ds in group_datasets if ds['is_excluded']]\n",
    "\n",
    "    # Included\n",
    "    for idx, ds in enumerate(included):\n",
    "        color = included_colors[idx % len(included_colors)]\n",
    "        dfp = ds['data'].copy()\n",
    "\n",
    "        dfp['time'] = (dfp['start_dates'] + dfp['end_dates']) / 2\n",
    "        dfp['errors_abs'] = dfp['errors'].abs()\n",
    "        dfp = dfp.sort_values('time').reset_index(drop=True)\n",
    "        if len(dfp) == 0:\n",
    "            continue\n",
    "\n",
    "        x_lines, y_lines = [], []\n",
    "        for _, row in dfp.iterrows():\n",
    "            x_lines.extend([row['start_dates'], row['end_dates'], np.nan])\n",
    "            y_lines.extend([row['changes'], row['changes'], np.nan])\n",
    "        ax.plot(x_lines, y_lines, '-', linewidth=2, alpha=0.7, color=color)\n",
    "\n",
    "        for _, row in dfp.iterrows():\n",
    "            x_ribbon = [row['start_dates'], row['end_dates'], row['end_dates'], row['start_dates']]\n",
    "            y_ribbon = [\n",
    "                row['changes'] - row['errors_abs'],\n",
    "                row['changes'] - row['errors_abs'],\n",
    "                row['changes'] + row['errors_abs'],\n",
    "                row['changes'] + row['errors_abs'],\n",
    "            ]\n",
    "            ax.fill(x_ribbon, y_ribbon, color=color, alpha=0.2, edgecolor='none')\n",
    "\n",
    "    # Excluded\n",
    "    for idx, ds in enumerate(excluded):\n",
    "        color = excluded_colors[idx % len(excluded_colors)]\n",
    "        dfp = ds['data'].copy()\n",
    "\n",
    "        dfp['time'] = (dfp['start_dates'] + dfp['end_dates']) / 2\n",
    "        dfp['errors_abs'] = dfp['errors'].abs()\n",
    "        dfp = dfp.sort_values('time').reset_index(drop=True)\n",
    "        if len(dfp) == 0:\n",
    "            continue\n",
    "\n",
    "        x_lines, y_lines = [], []\n",
    "        for _, row in dfp.iterrows():\n",
    "            x_lines.extend([row['start_dates'], row['end_dates'], np.nan])\n",
    "            y_lines.extend([row['changes'], row['changes'], np.nan])\n",
    "        ax.plot(x_lines, y_lines, '-', linewidth=2, alpha=0.7, color=color)\n",
    "\n",
    "        for _, row in dfp.iterrows():\n",
    "            x_ribbon = [row['start_dates'], row['end_dates'], row['end_dates'], row['start_dates']]\n",
    "            y_ribbon = [\n",
    "                row['changes'] - row['errors_abs'],\n",
    "                row['changes'] - row['errors_abs'],\n",
    "                row['changes'] + row['errors_abs'],\n",
    "                row['changes'] + row['errors_abs'],\n",
    "            ]\n",
    "            ax.fill(x_ribbon, y_ribbon, color=color, alpha=0.2, edgecolor='none')\n",
    "\n",
    "    # Legend\n",
    "    legend_elements = []\n",
    "    for idx, ds in enumerate(included):\n",
    "        color = included_colors[idx % len(included_colors)]\n",
    "        legend_elements.append(plt.Line2D([0], [0], color=color, lw=2,\n",
    "                                         label=f\"{ds['dataset']} (Included)\"))\n",
    "    for idx, ds in enumerate(excluded):\n",
    "        color = excluded_colors[idx % len(excluded_colors)]\n",
    "        legend_elements.append(plt.Line2D([0], [0], color=color, lw=2,\n",
    "                                         label=f\"{ds['dataset']} (Excluded)\"))\n",
    "\n",
    "    unit_label = 'Gravimetry (Gt)' if unit == 'Gt' else 'All Other Methods (m)'\n",
    "    ax.set_xlabel('Time (year)')\n",
    "    ax.set_ylabel(f'Change ({unit})')\n",
    "    ax.set_title(\n",
    "        f'{region.replace(\"_\", \" \").title()} ({unit_label})')\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "    if legend_elements:\n",
    "        ax.legend(handles=legend_elements, loc='best', fontsize=9, ncol=2)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    safe_region = region.replace('/', '_').replace('\\\\', '_')\n",
    "    output_path = output_dir_datasets / f\"{safe_region}_{unit}.png\"\n",
    "    plt.savefig(output_path, dpi=200, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
